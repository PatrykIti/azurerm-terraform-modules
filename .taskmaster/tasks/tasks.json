{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Repository and Directory Structure Setup",
        "description": "Initialize the Git repository on GitHub. Create the standard multi-module directory structure, including directories for modules, examples, and GitHub Actions workflows. Add foundational files like .gitignore, .editorconfig, and a root README.md.",
        "details": "Create a flat directory structure as per best practices. \n- `/modules`: Contains individual module directories (e.g., `storage_account`, `virtual_network`).\n- `/examples`: Contains usage examples, mirroring the module structure (e.g., `storage_account/simple`, `storage_account/complete`).\n- `/.github/workflows`: For CI/CD YAML files.\n- `/.tflint.hcl`: Configuration for tflint.\n- `/.checkov.yaml`: Configuration for Checkov.\n- Use a standard Terraform .gitignore file from github/gitignore.",
        "testStrategy": "Verify the repository is created on GitHub and the directory structure and essential configuration files (.gitignore, .editorconfig) exist on the main branch.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Add .editorconfig file for consistent code formatting",
            "description": "Create .editorconfig file with Terraform and YAML best practices",
            "details": "Create a comprehensive .editorconfig file in the repository root with the following specifications:\n\n1. Root declaration\n2. Global settings:\n   - charset = utf-8\n   - end_of_line = lf\n   - insert_final_newline = true\n   - trim_trailing_whitespace = true\n\n3. Terraform files (*.tf, *.tfvars):\n   - indent_style = space\n   - indent_size = 2\n\n4. YAML files (*.yml, *.yaml):\n   - indent_style = space\n   - indent_size = 2\n\n5. Markdown files (*.md):\n   - trim_trailing_whitespace = false (preserve trailing spaces for line breaks)\n\n6. Makefile:\n   - indent_style = tab\n\n7. Go files (*.go) for Terratest:\n   - indent_style = tab\n   - indent_size = 4\n\n8. JSON files (*.json):\n   - indent_style = space\n   - indent_size = 2",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          }
        ]
      },
      {
        "id": 2,
        "title": "CI/CD Foundation: Basic Validation Workflow",
        "description": "Create a foundational CI/CD pipeline using GitHub Actions that triggers on pull requests. This workflow will perform basic validation checks on the Terraform code.",
        "details": "Create a workflow file (e.g., `.github/workflows/validation.yml`). Use `actions/checkout@v4` and `hashicorp/setup-terraform@v3` with Terraform version `~> 1.8`. The workflow should have jobs for: \n1. `terraform fmt -check`: Checks formatting.\n2. `terraform init`: Initializes the backend for validation.\n3. `terraform validate`: Validates syntax. \nSet the workflow to trigger on `pull_request` events targeting the `main` branch.",
        "testStrategy": "Create a pull request with a correctly formatted Terraform file. The action should pass. Create another PR with a formatting error; the action should fail on the format check.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "CI/CD Integration: tflint and Checkov",
        "description": "Integrate static code analysis tools into the CI/CD pipeline to enforce code quality and security standards. This includes setting up tflint for linting and Checkov for security scanning.",
        "details": "Add new jobs to the `validation.yml` workflow. \n- **tflint**: Use `terraform-linters/setup-tflint-action@v4`. Configure `.tflint.hcl` to enable the Azure plugin and recommended rulesets. \n- **Checkov**: Use `bridgecrewio/checkov-action@v12`. Configure it to scan the `modules` directory and fail the build on medium or higher severity issues. Set a baseline with a `.checkov.yaml` file if needed.",
        "testStrategy": "Submit a PR with a Terraform resource that violates a tflint rule (e.g., non-standard tag). The tflint job should fail. Submit a PR with a security misconfiguration (e.g., a storage account allowing public access). The Checkov job should fail.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate tflint into CI/CD pipeline",
            "description": "Add tflint configuration and integrate it into GitHub Actions workflows",
            "details": "Complete tflint integration with the following steps:\n\n1. Create .tflint.hcl configuration file in repository root:\n   - Enable azurerm plugin (latest version)\n   - Configure recommended rules for Terraform best practices\n   - Set up rules for:\n     - terraform_deprecated_interpolation\n     - terraform_documented_outputs\n     - terraform_documented_variables\n     - terraform_naming_convention\n     - terraform_typed_variables\n     - terraform_unused_declarations\n     - terraform_required_version\n     - terraform_required_providers\n     - azurerm_resource_missing_tags\n\n2. Update pr-validation.yml workflow:\n   - Add tflint installation step using GitHub Action\n   - Run tflint on all Terraform modules\n   - Make it a required check for PR approval\n   - Add caching for tflint plugins\n\n3. Create module-specific .tflint.hcl files if needed:\n   - Override rules for specific modules\n   - Add module-specific plugin configurations\n\n4. Update security-scan-all.yml:\n   - Add tflint to the weekly security scan\n   - Generate tflint report for all modules\n\n5. Documentation:\n   - Update README.md with tflint usage instructions\n   - Add tflint badge to repository",
            "status": "done",
            "dependencies": [
              2
            ],
            "parentTaskId": 3
          }
        ]
      },
      {
        "id": 4,
        "title": "CI/CD Automation: terraform-docs Generation",
        "description": "Automate the generation of module documentation using terraform-docs. The CI/CD pipeline should update the README.md file within each module directory to reflect its inputs, outputs, and resources.",
        "details": "Create a new GitHub Actions workflow (`.github/workflows/docs.yml`) or add a job to the existing one. Use an action like `terraform-docs/gh-actions@v1`. Configure it to read a `.terraform-docs.yml` config file in each module's directory. The action should generate the documentation and commit the changes back to the feature branch if updates are detected.",
        "testStrategy": "Make a change to a module's `variables.tf` or `outputs.tf` file. Push the change to a PR branch. Verify that the GitHub Action automatically runs, generates updated documentation, and commits the new README.md to the branch.",
        "priority": "medium",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Terratest Framework and Helper Setup",
        "description": "Set up the Go environment and Terratest framework for end-to-end testing of modules. This includes creating a test directory, setting up helper functions for Azure authentication, and establishing a basic test case structure.",
        "details": "Create a `test/` directory at the root. Inside, initialize a Go module (`go mod init <repo_url>/test`). Add Terratest as a dependency: `go get github.com/gruntwork-io/terratest/modules/terraform`. Create a `helpers.go` file for common functions, such as authenticating to Azure using environment variables for a service principal, which will be provided as secrets in GitHub Actions.",
        "testStrategy": "Create a simple placeholder test file (`root_test.go`) that initializes Go modules and can be executed with `go test`. The test should pass, confirming the Go environment is correctly configured.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate semantic-release for automated CHANGELOG management",
            "description": "Replace manual CHANGELOG updates in module-release workflow with semantic-release integration for fully automated versioning and changelog generation",
            "details": "Implement semantic-release integration in the module-release.yml workflow to automate:\n1. Version determination based on conventional commits\n2. CHANGELOG generation following Keep a Changelog format\n3. Git tagging with module-specific prefixes (e.g., SAv1.2.3)\n4. GitHub release creation\n5. Automatic commit of updated files\n\nKey tasks:\n- Modify module-release.yml to use semantic-release instead of manual updates\n- Create shared .releaserc.js template for all modules\n- Ensure monorepo compatibility (each module releases independently)\n- Configure semantic-release to only analyze commits for specific module paths\n- Update documentation in WORKFLOWS.md and CLAUDE.md",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          }
        ]
      },
      {
        "id": 6,
        "title": "Storage Account Module: Core Implementation",
        "description": "Refactor the core Storage Account module (`azurerm_storage_account`) to comply with AzureRM provider v5.0. This involves replacing deprecated inline blocks with separate resources, updating variable structures, and ensuring all features like static websites, queue properties, and lifecycle rules are implemented using the latest best practices.",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "Update the module to align with `azurerm` provider v5.0. Key changes include:\n1. Removing the deprecated `static_website` and `queue_properties` blocks from the `azurerm_storage_account` resource.\n2. Implementing these features using the new standalone resources: `azurerm_storage_account_static_website` and `azurerm_storage_account_queue_properties`.\n3. Refactoring input variables (e.g., `static_website`, `queue_properties`) to be complex objects with empty object `{}` defaults, moving default values into `optional()` parameters.\n4. Adding conditional creation logic for the new resources based on whether the corresponding input variable object is empty.",
        "testStrategy": "Update and execute all existing examples (simple, complete, multi-region, secure, secure-private-endpoint) to validate the refactored module. Specifically verify:\n1. Correct creation of the main storage account.\n2. Conditional creation of the `azurerm_storage_account_static_website` and `azurerm_storage_account_queue_properties` resources.\n3. Functionality of lifecycle rules, noting the incompatibility of the 'Archive' tier with ZRS accounts.\n4. All outputs, including new ones for static website and corrected private endpoint references, are populated correctly.",
        "subtasks": [
          {
            "id": 2,
            "title": "Define Input Variables in `variables.tf`",
            "description": "Create the `variables.tf` file and define all the necessary input variables for the storage account module.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "In `modules/storage_account/variables.tf`, refactor all input variables to follow modern Terraform best practices. This includes defining complex object variables for `static_website` and `queue_properties` to control the new standalone resources. Set the default value for these optional configurations to an empty object `{}` and define nested attribute defaults using the `optional()` function.",
            "testStrategy": "Create a root module that calls this module. Run `terraform plan` and ensure that Terraform prompts for any variables that do not have default values."
          },
          {
            "id": 3,
            "title": "Implement Input Validation",
            "description": "Add validation blocks to the input variables to enforce specific constraints and prevent misconfiguration.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "In `variables.tf`, add `validation` blocks to the `account_tier` and `account_replication_type` variables. The `account_tier` should only allow 'Standard' or 'Premium'. The `account_replication_type` should only allow valid Azure replication types (e.g., 'LRS', 'GRS', 'ZRS', 'RAGRS'). For complex object variables, validation is handled by their type constraints and `optional()` definitions.",
            "testStrategy": "Attempt to run `terraform plan` with invalid values for `account_tier` (e.g., 'Basic') and `account_replication_type` (e.g., 'INVALID'). Verify that the plan fails with the custom error messages from the validation blocks."
          },
          {
            "id": 4,
            "title": "Implement Core `azurerm_storage_account` Resource",
            "description": "Create the `main.tf` file and define the core `azurerm_storage_account` resource using the defined variables.",
            "status": "done",
            "dependencies": [
              3
            ],
            "details": "In `modules/storage_account/main.tf`, update the `azurerm_storage_account` resource block. **Crucially, remove the deprecated `static_website` and `queue_properties` inline blocks.** Ensure all other arguments (`name`, `resource_group_name`, `location`, etc.) are correctly mapped from their input variables.",
            "testStrategy": "Run `terraform apply` using a root module with valid inputs. Verify in the Azure Portal or via Azure CLI that the storage account is created with the specified configuration."
          },
          {
            "id": 5,
            "title": "Configure Basic Blob Service Properties",
            "description": "Enhance the storage account resource to support basic blob service configurations.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "In `main.tf`, add a `blob_properties` block to the `azurerm_storage_account` resource. Add a new optional variable to control the `delete_retention_policy` days for blobs.",
            "testStrategy": "Apply the configuration with a specific value for the blob delete retention policy. Verify in the Azure Portal that the 'Soft delete for blobs' setting on the storage account matches the configured value."
          },
          {
            "id": 6,
            "title": "Configure Basic File Share Properties",
            "description": "Enhance the storage account resource to support basic file share service configurations.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "In `main.tf`, add a `share_properties` block to the `azurerm_storage_account` resource. Add a new optional variable to control the `delete_retention_policy` days for file shares.",
            "testStrategy": "Apply the configuration with a specific value for the file share delete retention policy. Verify in the Azure Portal that the 'Soft delete for file shares' setting on the storage account matches the configured value."
          },
          {
            "id": 7,
            "title": "Define Module Outputs in `outputs.tf`",
            "description": "Create the `outputs.tf` file to expose key attributes of the created storage account for use by other modules.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "In `modules/storage_account/outputs.tf`, update and add outputs to reflect the new resources. Add outputs for the `azurerm_storage_account_static_website` (e.g., `static_website_endpoints`) and `azurerm_storage_account_queue_properties` resources. Ensure existing outputs like `primary_connection_string` (marked as sensitive) are preserved. Use `try()` for safe access to outputs from conditionally created resources.\n<info added on 2025-07-03T15:56:13.278Z>\nTesting of configured Terraform tools is complete:\n- terraform fmt: Passed after fixing formatting in 18 files.\n- terraform validate: Passed after provider upgrade to 4.35.0.\n- tflint: Passed with 2 warnings for deprecated variables (azure_files_authentication, customer_managed_key).\n- terraform-docs: Passed after fixing config template.\n- checkov: Partial pass due to a tool bug with network rule parsing. Scan found 90 passed and 85 failed checks, mostly in examples.\nAll major tools are configured and working. The module passes all validation and linting checks.\n</info added on 2025-07-03T15:56:13.278Z>\n<info added on 2025-07-03T16:02:01.340Z>\nCompleted testing all configured Terraform tools and cleaned up module documentation.\n\nTool Testing Results:\n- terraform fmt - PASSED: Fixed formatting issues in 18 files across module and examples. All files are now properly formatted.\n- terraform validate - PASSED: Module validates successfully with azurerm provider 4.35.0. All syntax and configuration is valid.\n- tflint - PASSED (with warnings): Version 0.58.0 installed and configured. Found 2 unused, deprecated variables: azure_files_authentication, customer_managed_key. No critical issues found.\n- terraform-docs - PASSED: Version 0.20.0 installed. Custom .terraform-docs.yml configuration is working after fixing a template issue.\n- checkov - PARTIAL: Version 3.2.447 installed. Security scan has internal errors with network bypass parsing. Found 90 passed checks and 85 failed (mostly in examples due to demo configurations).\n\nDocumentation Cleanup:\n- Removed duplicate manual content from README.md.\n- Left only terraform-docs markers for automatic generation.\n- Documentation is now fully managed by terraform-docs and the CI/CD workflow.\n\nAll major tools are properly configured and the module passes all critical validation checks.\n</info added on 2025-07-03T16:02:01.340Z>\n<info added on 2025-07-03T19:20:40.698Z>\nModule outputs update is complete. Added outputs for static_website and queue_properties, and fixed private endpoint references. All outputs are tested and working. The module is now fully refactored for azurerm v5.0, with all examples tested and working on Azure. CI/CD workflows have been created with correct paths and the `SAv*` tag format.\n</info added on 2025-07-03T19:20:40.698Z>",
            "testStrategy": "After a successful `terraform apply`, run `terraform output` in the root module. Verify that all defined outputs are present and display correct, non-null values. Check that the sensitive connection string is redacted."
          },
          {
            "id": 8,
            "title": "Create Initial Module Documentation (README.md)",
            "description": "Create a `README.md` file to document the module's purpose, usage, inputs, and outputs.",
            "status": "done",
            "dependencies": [
              3,
              7
            ],
            "details": "Update the `README.md` file to reflect the module's new structure and variable formats. Update the usage examples to show how to configure the static website and queue properties using the new complex object variables. Ensure the input and output tables are accurate and document the new conditional resources.",
            "testStrategy": "Perform a peer review of the `README.md` file. Ensure it is clear, accurate, and provides a complete usage example that can be copied and used directly."
          },
          {
            "id": 9,
            "title": "Implement `azurerm_storage_account_static_website` Resource",
            "description": "Create the standalone resource for static website hosting, replacing the deprecated inline block.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "In `main.tf`, add a new `azurerm_storage_account_static_website` resource. Use a `count` or `for_each` meta-argument to create this resource conditionally, only when the `var.static_website` object is not empty. Map the resource arguments to the attributes of the `var.static_website` variable.",
            "testStrategy": "Deploy the module with the `static_website` variable configured. Verify the resource is created and the static website feature is enabled on the storage account in the Azure Portal. Deploy again with an empty object to verify the resource is destroyed."
          },
          {
            "id": 10,
            "title": "Implement `azurerm_storage_account_queue_properties` Resource",
            "description": "Create the standalone resource for queue properties, replacing the deprecated inline block.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "In `main.tf`, add a new `azurerm_storage_account_queue_properties` resource. Use a `count` or `for_each` meta-argument to create this resource conditionally, only when the `var.queue_properties` object is not empty. Map the resource arguments to the attributes of the `var.queue_properties` variable.",
            "testStrategy": "Deploy the module with the `queue_properties` variable configured (e.g., with logging). Verify the resource is created and the queue properties are set correctly in the Azure Portal. Deploy again with an empty object to verify the resource is destroyed."
          },
          {
            "id": 11,
            "title": "Implement Storage Lifecycle Management Rules",
            "description": "Add support for `azurerm_storage_management_lifecycle_rule` to manage data lifecycle.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "Add support for `azurerm_storage_management_lifecycle_rule` resources. Create a new complex object variable `lifecycle_rules` to define rule sets. Implement the resource using a `for_each` loop over the variable. Ensure documentation and examples note that the 'Archive' tier action is not compatible with ZRS replication types.",
            "testStrategy": "Deploy the module with a lifecycle rule defined for a non-ZRS account. Verify the rule is created in the Azure Portal. Attempt to deploy a rule with an 'Archive' action for a ZRS account and verify that if not handled, it fails as expected."
          },
          {
            "id": 1,
            "title": "Initialize Module Directory Structure",
            "description": "Create the necessary directory for the new storage account module.",
            "dependencies": [],
            "details": "Create a new directory named `storage_account` inside the `modules/` directory. This will house all the Terraform files for this module.",
            "status": "done",
            "testStrategy": "Verify that the `modules/storage_account` directory exists in the repository structure."
          }
        ]
      },
      {
        "id": 7,
        "title": "Storage Account Module: Enterprise and Security Features",
        "description": "Enhance the Storage Account module with enterprise-grade security and operational features, including diagnostic settings, private endpoint support, network rules, and customer-managed key integration.",
        "details": "Add resources and variables to the Storage Account module: \n- `azurerm_monitor_diagnostic_setting`: To send logs and metrics to a Log Analytics Workspace. \n- `azurerm_private_endpoint`: Conditionally created based on a variable. \n- `network_rules` block within `azurerm_storage_account`: To configure firewall settings. \n- `customer_managed_key` block: To integrate with Azure Key Vault. \n- Enforce `min_tls_version = \"1.2\"` and `https_only = true` as secure defaults, which can be overridden if necessary.",
        "testStrategy": "Extend the manual deployment test. Deploy the module with diagnostic settings enabled and verify logs are flowing to Log Analytics. Deploy with a private endpoint and confirm public network access is denied. Check security settings in the Azure portal.",
        "priority": "high",
        "dependencies": [
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Storage Account Module: Terratest Suite and Examples",
        "description": "Create a comprehensive test suite for the Storage Account module using Terratest. Develop simple and complete usage examples in the `/examples` directory.",
        "details": "In the `test/` directory, create `storage_account_test.go`. Write test cases using `t.Run` for different scenarios: \n1. A minimal deployment. \n2. A complex deployment with private endpoints and network rules. \nUse `terraform.InitAndApply` and `defer terraform.Destroy`. Use `azure.GetStorageAccount` from Terratest helpers to assert that the created resource has the correct properties. Create corresponding `examples/storage_account/simple` and `examples/storage_account/complete` directories with `main.tf` files demonstrating usage.",
        "testStrategy": "Run `go test -v -timeout 15m ./...` from the `test/` directory. The GitHub Actions workflow for testing should execute this command against a test Azure subscription. All tests must pass, and resources must be successfully destroyed.",
        "priority": "high",
        "dependencies": [
          5,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Virtual Network Module: Core Implementation",
        "description": "Develop the Virtual Network module (`azurerm_virtual_network`). This module will manage VNet creation, address spaces, and the configuration of one or more subnets with associated Network Security Groups (NSGs).",
        "details": "Create `modules/virtual_network`. The module should accept a variable for the main address space and a complex variable (e.g., a map of objects) for defining subnets. For each subnet, allow specifying its name, address prefix, and an option to create a default NSG. Use a `for_each` loop to create `azurerm_subnet` and `azurerm_network_security_group` resources based on the input map.",
        "testStrategy": "Manually deploy the module with a configuration for a VNet and two subnets. Verify in the Azure portal that the VNet and subnets are created with the correct address prefixes and that the NSGs are associated correctly.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Virtual Network Module: Terratest Suite and Examples",
        "description": "Create a comprehensive test suite for the Virtual Network module using Terratest and develop corresponding usage examples.",
        "details": "Create `test/virtual_network_test.go`. Write Terratest cases to validate: \n1. VNet and subnet creation with correct CIDR blocks. \n2. NSG association. \nUse `azure.GetVirtualNetwork` and `azure.GetSubnet` to fetch the deployed resources and assert their properties. Create `examples/virtual_network/simple` (VNet with one subnet) and `examples/virtual_network/complete` (VNet with multiple subnets and custom NSG rules).",
        "testStrategy": "Execute the Terratest suite for the VNet module via the CI pipeline. All tests should pass, confirming resource creation and properties, followed by successful cleanup.",
        "priority": "medium",
        "dependencies": [
          5,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Key Vault Module: Core Implementation",
        "description": "Develop the Key Vault module (`azurerm_key_vault`). The module will handle Key Vault creation, access policies, SKU selection, and secure defaults like soft delete and purge protection.",
        "details": "Create `modules/key_vault`. The `main.tf` should include the `azurerm_key_vault` resource. Implement secure defaults: `soft_delete_retention_days = 7` and `purge_protection_enabled = true`. Use a dynamic block to configure `access_policy` based on a list of object IDs. Include support for private endpoints and diagnostic settings, similar to the Storage Account module.",
        "testStrategy": "Manually deploy the module. Verify in the Azure portal that the Key Vault is created with soft delete and purge protection enabled by default. Check that the specified access policies are correctly configured.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Key Vault Module: Terratest Suite and Examples",
        "description": "Create a comprehensive test suite for the Key Vault module using Terratest and develop corresponding usage examples.",
        "details": "Create `test/key_vault_test.go`. Write Terratest cases to validate: \n1. Key Vault creation with correct SKU and security settings. \n2. Correct application of access policies. \nUse `azure.GetKeyVault` to assert properties. Create `examples/key_vault/simple` and `examples/key_vault/with_private_endpoint` to demonstrate different use cases.",
        "testStrategy": "Execute the Terratest suite for the Key Vault module via the CI pipeline. All tests must pass, confirming resource creation and properties, followed by successful cleanup.",
        "priority": "medium",
        "dependencies": [
          5,
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Application Gateway Module: Core Implementation",
        "description": "Develop the Application Gateway module (`azurerm_application_gateway`). This complex module will manage the gateway itself, public IP, listeners, backend pools, and routing rules.",
        "details": "Create `modules/application_gateway`. This module will require a complex variable structure to define the frontend/backend configuration. The `main.tf` will orchestrate `azurerm_public_ip`, `azurerm_application_gateway`, and its sub-resources (`frontend_ip_configuration`, `frontend_port`, `backend_address_pool`, `http_listener`, `request_routing_rule`). The module must depend on a VNet and subnet created by the Virtual Network module.",
        "testStrategy": "Due to its complexity, initial testing will be a manual deployment. Deploy the module into a pre-existing VNet. Verify in the Azure portal that all components (gateway, IP, listener, rules) are configured as specified in the input variables.",
        "priority": "low",
        "dependencies": [
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Application Gateway Module: Terratest Suite and Examples",
        "description": "Create a comprehensive test suite for the Application Gateway module using Terratest and develop corresponding usage examples.",
        "details": "Create `test/application_gateway_test.go`. This test will be more involved. It should deploy a prerequisite VNet and a backend VM (using a simple VM module or local-exec provisioner) to act as a target. The test will then deploy the Application Gateway and make an HTTP request to its public IP to verify a `200 OK` response. Create `examples/application_gateway/simple_gateway` to show a basic setup.",
        "testStrategy": "Execute the Terratest suite for the Application Gateway. This test will take longer but must verify end-to-end functionality by successfully receiving an HTTP response from the backend through the gateway.",
        "priority": "low",
        "dependencies": [
          5,
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "CI/CD Automation: Semantic Versioning and Release Workflow",
        "description": "Implement a GitHub Actions workflow for release management. The workflow will automate the process of tagging and releasing new module versions based on semantic versioning and conventional commits.",
        "details": "Create a workflow (`.github/workflows/release.yml`) that triggers on pushes to the `main` branch. Use a tool like `go-semantic-release` or a custom script to: \n1. Analyze commit messages since the last tag (following Conventional Commits). \n2. Determine the next version number (patch, minor, or major). \n3. Create and push a new Git tag in the format `<module-name>/vX.Y.Z`. \n4. Create a GitHub Release with auto-generated release notes. \nThis requires a strategy to identify which module was changed in a commit.",
        "testStrategy": "Make a `feat:` commit to the Storage Account module on a feature branch and merge it to `main`. Verify that the release workflow triggers, creates a new tag (e.g., `storage_account/v1.0.0`), and publishes a corresponding GitHub Release.",
        "priority": "medium",
        "dependencies": [
          3,
          4,
          8,
          10,
          12,
          14
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement GitHub Actions CI/CD Workflows for Modules and Repository",
        "description": "Establish a comprehensive CI/CD pipeline using GitHub Actions, including repository-level workflows for global checks and module-specific workflows for individual module testing and release.",
        "details": "Implement a multi-faceted GitHub Actions strategy. For repository-level concerns, create a `.github/workflows/pr-validation.yml` that triggers on pull requests to `main`. This workflow will expand on the basic validation by running `terraform fmt`, `tflint`, and `checkov` across all modified modules. For module-specific CI, create workflows like `.github/workflows/azurerm-storage-account-ci.yml`. These will trigger on path-specific changes (e.g., `paths: ['modules/storage_account/**']`) and execute the module's Terratest suite using Azure credentials stored as GitHub secrets. For releases, create corresponding workflows like `azurerm-storage-account-release.yml` that trigger on version tags (e.g., `storage-account/v*.*.*`) to automate the creation of GitHub Releases, ensuring independent module versioning.",
        "testStrategy": "Verify repository-level workflows by creating a PR with a linting error, which should cause the `pr-validation.yml` to fail. A subsequent fix should make it pass. For module-level CI, push a change to the `storage_account` module and confirm that only its specific CI workflow (`azurerm-storage-account-ci.yml`) and the global PR validation workflow are triggered. The CI workflow must successfully execute the Terratest suite. Finally, test the release process by pushing a tag like `storage-account/v1.0.0` and verifying that the release workflow runs and creates a corresponding release on GitHub.",
        "status": "pending",
        "dependencies": [
          1,
          2,
          5,
          8,
          10,
          12
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Standardize azurerm Provider Version to 4.35.0",
        "description": "Pin the `azurerm` provider version to exactly `4.35.0` across all Terraform modules. This ensures consistent behavior and predictable deployments by preventing automatic provider upgrades.",
        "details": "For each module in the `modules/` directory (e.g., `storage_account`, `virtual_network`, `key_vault`, `application_gateway`), locate or create a `versions.tf` file. Inside this file, add or update the `terraform` block to specify the exact provider version. The configuration should be: `terraform { required_providers { azurerm = { source = \"hashicorp/azurerm\", version = \"= 4.35.0\" } } }`. After updating the files, run `terraform init` within each module's primary example directory to update the `.terraform.lock.hcl` file. Commit both the changes to the `versions.tf` files and the updated lock file to the repository.",
        "testStrategy": "1. Verify that every module directory under `modules/` contains a `versions.tf` file with the `azurerm` provider pinned to version `= 4.35.0`. 2. Pull the changes locally and run `terraform init` in at least two different module example directories (e.g., `examples/storage_account/simple` and `examples/application_gateway/simple_gateway`) to confirm successful initialization with the specified provider version. 3. Push the changes to a new branch and create a pull request. The CI/CD validation workflow must pass, confirming that `terraform validate` and `tflint` succeed for all modules with the pinned provider version.",
        "status": "pending",
        "dependencies": [
          13,
          16
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Enhance Storage Account Module with Additional Parameters and Fixes",
        "description": "Update the `azurerm_storage_account` module to support new features by adding missing parameters (e.g., HNS, SFTP, OAuth) and complex configuration blocks (e.g., SAS policy, immutability). This task also includes fixes for validation rules on existing parameters.",
        "details": "This task involves a significant feature expansion of the Storage Account module. \n\n**High Priority Parameters:**\nAdd the following optional arguments to the `azurerm_storage_account` resource in `main.tf`, controlled by new variables in `variables.tf` with `null` defaults:\n- `is_hns_enabled` (bool)\n- `cross_tenant_replication_enabled` (bool)\n- `default_to_oauth_authentication` (bool)\n- `sftp_enabled` (bool)\n- `nfsv3_enabled` (bool)\n- `allowed_copy_scope` (string)\n- `queue_encryption_key_type` (string)\n- `table_encryption_key_type` (string)\n- `local_user_enabled` (bool)\n- `edge_zone` (string)\n- `large_file_share_enabled` (bool)\n\n**Medium Priority Blocks:**\nImplement support for the following nested blocks using dynamic blocks and complex object variables:\n- `immutability_policy`: Define a variable `var.immutability_policy` of type object to configure the policy.\n- `sas_policy`: Define `var.sas_policy` to set expiration and type.\n- `routing`: Define `var.routing` to manage routing preferences.\n- `custom_domain`: Define `var.custom_domain` to associate a custom domain.\n- `share_properties`: Define `var.share_properties` to configure SMB settings like `smb_multichannel_enabled`.\n\n**Validation Fixes:**\n1. In `variables.tf`, locate the `min_tls_version` variable and update its `validation` block to include 'TLS1_0', 'TLS1_1', and 'TLS1_2' in the list of allowed values.\n2. Locate the `access_tier` variable and update its `validation` block to add 'Premium' to the allowed values. Note that 'Premium' is only valid for specific `account_kind` values, which should be documented.",
        "testStrategy": "1. **Validation Fix:** Update an existing example to set `min_tls_version = \"TLS1_1\"` and verify a successful `terraform apply`. Create a new example for a premium block blob storage account (`account_kind = \"BlockBlobStorage\"`, `account_tier = \"Premium\"`) and verify it deploys successfully.\n2. **High-Priority Parameters:** Update the `complete` example to enable SFTP (`sftp_enabled = true`) and Hierarchical Namespace (`is_hns_enabled = true`). Deploy the example and verify in the Azure Portal that the storage account is configured as a Data Lake Gen2 with SFTP enabled.\n3. **Medium-Priority Blocks:** Create a new example (`examples/storage_account/advanced-policies`) that defines variables for `sas_policy` and `share_properties`. Deploy and use Azure CLI or the Portal to confirm that the SAS policy (e.g., expiration period) and the SMB share properties are correctly set on the deployed account.\n4. **Regression:** Execute all existing examples for the storage account module to ensure that these additions do not break existing functionality for users who do not specify the new variables.",
        "status": "done",
        "dependencies": [
          6
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Fix Validation for min_tls_version and access_tier Parameters",
            "description": "Update the validation rules for `min_tls_version` and `access_tier` variables in `variables.tf` to include newly supported values and improve documentation.",
            "dependencies": [],
            "details": "1. Open the `variables.tf` file for the module.\n2. Locate the `min_tls_version` variable definition.\n3. Modify its `validation` block's `condition` to include 'TLS1_0', 'TLS1_1', and 'TLS1_2' in the list of allowed values. The condition should look like: `can(regex(\"^(TLS1_0|TLS1_1|TLS1_2)$\"), var.min_tls_version))`. \n4. Locate the `access_tier` variable definition.\n5. Modify its `validation` block's `condition` to add 'Premium' to the list of allowed values. The condition should look like: `can(regex(\"^(Hot|Cool|Premium)$\"), var.access_tier))`. \n6. Add a comment to the `description` of the `access_tier` variable stating that 'Premium' is only valid for `account_kind` values 'BlockBlobStorage' and 'FileStorage'.\n<info added on 2025-07-06T18:56:01.916Z>\nMANDATORY requirement: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9), and section 9: Terraform Best Practices Guide (lines 112-122) for variable design patterns and validation rules. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files.\n</info added on 2025-07-06T18:56:01.916Z>",
            "status": "done",
            "testStrategy": "Run `terraform validate` after changes. Create a test configuration that sets `min_tls_version = \"TLS1_0\"` and another that sets `access_tier = \"Premium\"` (with a compatible `account_kind`) and run `terraform plan` to ensure validation passes. Test with an invalid value to confirm failure."
          },
          {
            "id": 2,
            "title": "Add Data Lake Gen2 and Protocol Support Parameters",
            "description": "Implement support for Data Lake Gen2 (HNS), SFTP, NFSv3, and local user access by adding the corresponding optional boolean parameters to the module.",
            "dependencies": [],
            "details": "1. In `variables.tf`, declare the following new variables with `type = bool` and `default = null`:\n   - `is_hns_enabled`\n   - `sftp_enabled`\n   - `nfsv3_enabled`\n   - `local_user_enabled`\n2. In `main.tf`, update the `azurerm_storage_account` resource block to include these new arguments, assigning them their corresponding variable values (e.g., `is_hns_enabled = var.is_hns_enabled`).\n<info added on 2025-07-06T18:56:21.034Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122) for variable design patterns. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Follow variable naming conventions and use appropriate defaults (null for optional parameters).\n</info added on 2025-07-06T18:56:21.034Z>",
            "status": "done",
            "testStrategy": "For each new parameter, create a test case setting it to `true`. Run `terraform plan` and verify that the plan output shows the corresponding attribute being enabled on the `azurerm_storage_account` resource."
          },
          {
            "id": 3,
            "title": "Add Security Control Parameters for Replication, Auth, and Copy Scope",
            "description": "Enhance security options by adding parameters for cross-tenant replication, OAuth authentication default, and allowed copy scope.",
            "dependencies": [],
            "details": "1. In `variables.tf`, declare the following new variables with `default = null`:\n   - `cross_tenant_replication_enabled` (type = bool)\n   - `default_to_oauth_authentication` (type = bool)\n   - `allowed_copy_scope` (type = string)\n2. In `main.tf`, update the `azurerm_storage_account` resource block to include these new arguments, assigning them their corresponding variable values (e.g., `cross_tenant_replication_enabled = var.cross_tenant_replication_enabled`).\n<info added on 2025-07-06T18:56:33.465Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122), especially the security best practices section. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Follow security best practices when implementing authentication and access control parameters.\n</info added on 2025-07-06T18:56:33.465Z>",
            "status": "done",
            "testStrategy": "Create a test configuration that sets non-default values for these parameters (e.g., `default_to_oauth_authentication = true`, `allowed_copy_scope = \"PrivateLink\"`). Run `terraform plan` and confirm the plan reflects these settings."
          },
          {
            "id": 4,
            "title": "Add Encryption Key Type Parameters for Queues and Tables",
            "description": "Add optional string parameters to specify the encryption key type ('Service' or 'Account') for queue and table services.",
            "dependencies": [],
            "details": "1. In `variables.tf`, declare the following new variables with `type = string` and `default = null`:\n   - `queue_encryption_key_type`\n   - `table_encryption_key_type`\n2. Add a `validation` block to each new variable to ensure the value is one of 'Service' or 'Account'. Example condition: `var.queue_encryption_key_type == null || contains([\"Service\", \"Account\"], var.queue_encryption_key_type)`.\n3. In `main.tf`, update the `azurerm_storage_account` resource block to include the `queue_encryption_key_type` and `table_encryption_key_type` arguments, assigning them their corresponding variable values.\n<info added on 2025-07-06T18:56:52.061Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122) for variable design patterns and validation. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Use proper validation blocks to ensure parameters only accept valid values (Service or Account).\n</info added on 2025-07-06T18:56:52.061Z>",
            "status": "done",
            "testStrategy": "Create a test case setting `queue_encryption_key_type = \"Account\"` and `table_encryption_key_type = \"Account\"`. Run `terraform plan` and verify the plan shows these values being set on the resource."
          },
          {
            "id": 5,
            "title": "Add Infrastructure Parameters for Large File Shares and Edge Zone",
            "description": "Implement support for enabling large file shares and specifying an edge zone for the storage account deployment.",
            "dependencies": [],
            "details": "1. In `variables.tf`, declare the following new variables with `default = null`:\n   - `large_file_share_enabled` (type = bool)\n   - `edge_zone` (type = string)\n2. In `main.tf`, update the `azurerm_storage_account` resource block to include the `large_file_share_enabled` and `edge_zone` arguments, assigning them their corresponding variable values.\n<info added on 2025-07-06T18:57:09.355Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122) for variable design patterns. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Infrastructure parameters should use null defaults to maintain backward compatibility.\n</info added on 2025-07-06T18:57:09.355Z>",
            "status": "done",
            "testStrategy": "Create a test case setting `large_file_share_enabled = true` and `edge_zone` to a valid Azure Edge Zone name. Run `terraform plan` and verify the plan output reflects these settings."
          },
          {
            "id": 6,
            "title": "Implement Immutability Policy and SAS Policy Configuration Blocks",
            "description": "Add support for configuring container immutability and account-level SAS policies using dynamic blocks based on new object variables.",
            "dependencies": [],
            "details": "1. In `variables.tf`, define `var.immutability_policy` with type `object({ allow_protected_append_writes = bool, period_in_days = number })` and `default = null`.\n2. In `variables.tf`, define `var.sas_policy` with type `object({ expiration_period = string, expiration_action = string })` and `default = null`.\n3. In `main.tf`, within the `azurerm_storage_account` resource, add a `dynamic \"immutability_policy\"` block. Use `for_each = var.immutability_policy != null ? [var.immutability_policy] : []`. Inside `content`, map the object attributes to the block arguments.\n4. In `main.tf`, add a `dynamic \"sas_policy\"` block. Use `for_each = var.sas_policy != null ? [var.sas_policy] : []`. Inside `content`, map the object attributes.\n<info added on 2025-07-06T18:57:29.284Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122) especially variable design patterns for complex objects. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Use object types for grouping related parameters logically as suggested by user.\n</info added on 2025-07-06T18:57:29.284Z>",
            "status": "done",
            "testStrategy": "Create a test configuration providing a valid object for `immutability_policy` and `sas_policy`. Run `terraform plan` and inspect the output to ensure the dynamic blocks are generated correctly with the specified values."
          },
          {
            "id": 7,
            "title": "Implement Routing and Custom Domain Configuration Blocks",
            "description": "Add support for configuring routing preferences and custom domains using dynamic blocks based on new object variables.",
            "dependencies": [],
            "details": "1. In `variables.tf`, define `var.routing` with type `object({ choice = string, publish_internet_endpoints = bool, publish_microsoft_endpoints = bool })` and `default = null`.\n2. In `variables.tf`, define `var.custom_domain` with type `object({ name = string, use_subdomain_name = optional(bool) })` and `default = null`.\n3. In `main.tf`, within the `azurerm_storage_account` resource, add a `dynamic \"routing\"` block. Use `for_each = var.routing != null ? [var.routing] : []`. Map attributes in the `content` block.\n4. In `main.tf`, add a `dynamic \"custom_domain\"` block. Use `for_each = var.custom_domain != null ? [var.custom_domain] : []`. Map attributes in the `content` block.\n<info added on 2025-07-06T18:57:42.746Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122), especially regarding variable design patterns for complex objects. Key principles: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Use object types with optional() for non-required fields within objects.\n</info added on 2025-07-06T18:57:42.746Z>",
            "status": "done",
            "testStrategy": "Provide test objects for `routing` and `custom_domain` variables. Run `terraform plan` and verify that the execution plan includes the correctly configured `routing` and `custom_domain` blocks for the storage account."
          },
          {
            "id": 8,
            "title": "Implement Share Properties Configuration Block",
            "description": "Add support for configuring file share properties, such as SMB settings and retention policies, using a dynamic block.",
            "dependencies": [],
            "details": "1. In `variables.tf`, define a new complex object variable `var.share_properties` with a `default = null`. The object structure should mirror the `share_properties` block in the `azurerm_storage_account` resource, including attributes for `smb`, `cors_rule`, and `retention_policy`.\n2. In `main.tf`, within the `azurerm_storage_account` resource, add a `dynamic \"share_properties\"` block.\n3. Use the pattern `for_each = var.share_properties != null ? [var.share_properties] : []` to conditionally create the block.\n4. Inside the `content` block, map the attributes from the `var.share_properties` object. This will require nested dynamic blocks for list attributes like `cors_rule`.\n<info added on 2025-07-06T18:57:58.447Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122), especially regarding variable design patterns for complex nested objects. Key principles to follow: Do what has been asked; nothing more, nothing less. ALWAYS prefer editing existing files. NEVER create new files. Complex objects with nested structures require careful implementation of dynamic blocks.\n</info added on 2025-07-06T18:57:58.447Z>",
            "status": "done",
            "testStrategy": "Define a complex `share_properties` object in a test `.tfvars` file, including SMB settings and a CORS rule. Run `terraform plan` and carefully inspect the plan output to ensure all nested properties are correctly configured."
          }
        ]
      },
      {
        "id": 19,
        "title": "Comprehensive Update of Storage Account Module Outputs",
        "description": "Conduct a comprehensive review and update of the `outputs.tf` file for the `azurerm_storage_account` module. This involves adding, correcting, and removing outputs for all associated resources to ensure all useful attributes are exposed.",
        "details": "The goal is to align all outputs with the latest Terraform AzureRM provider documentation. Review the documentation for each of the following resources within the module: `azurerm_storage_account`, `azurerm_storage_container`, `azurerm_storage_queue`, `azurerm_storage_share`, `azurerm_storage_table`, `azurerm_private_endpoint`, `azurerm_storage_account_queue_properties`, `azurerm_storage_account_static_website`, `azurerm_storage_management_policy`, and `azurerm_monitor_diagnostic_setting`. For each resource, identify all exported attributes that provide value to the end-user. Add new `output` blocks for missing attributes, correct the `value` of any incorrect outputs, and remove any outputs that reference deprecated attributes. Ensure all outputs have a clear and concise `description`. For example, for `azurerm_storage_account`, ensure outputs like `primary_web_endpoint`, `primary_dfs_endpoint`, and the full `identity` block are exposed. For `azurerm_storage_container`, expose `id`, `name`, and `resource_manager_id`.",
        "testStrategy": "1. Update the `complete` example in `examples/storage_account/complete` to include a local `outputs.tf` file that references all the newly added and updated outputs from the module. 2. Run `terraform init` and `terraform apply` on this example to deploy the resources. 3. After a successful deployment, run `terraform output` and inspect the values to ensure they are not null or empty and appear correct. 4. Cross-reference at least five key output values (e.g., `primary_blob_endpoint`, a container ID, a private endpoint ID) with the actual resource properties in the Azure Portal to confirm accuracy. 5. Run `terraform destroy` and verify all resources are cleaned up successfully.",
        "status": "done",
        "dependencies": [
          6,
          18
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Review and Update `azurerm_storage_account` Outputs",
            "description": "Conduct a thorough review of the `azurerm_storage_account` resource attributes against the official Terraform AzureRM provider documentation. Update the `outputs.tf` file to add, correct, or remove outputs to ensure all valuable attributes are exposed.",
            "dependencies": [],
            "details": "1. Access the Terraform Registry page for the `azurerm_storage_account` resource.\n2. Compile a list of all exported attributes.\n3. Compare this list with the existing outputs in the module's `outputs.tf` file.\n4. Add new `output` blocks for high-value missing attributes like `primary_web_endpoint`, `primary_dfs_endpoint`, `secondary_location`, and the `identity` block.\n5. Correct the `value` of any outputs that are misconfigured.\n6. Remove any outputs that reference deprecated attributes.\n7. Ensure every output has a clear and concise `description`.\n<info added on 2025-07-07T05:55:31.685Z>\nMANDATORY requirement: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) - especially \"Do what has been asked; nothing more, nothing less\" and \"ALWAYS prefer editing existing files\", and section 9: Terraform Best Practices Guide (lines 112-122) for module documentation standards. Key principles: Edit only outputs.tf file, do not create new files, ensure all outputs have clear descriptions.\n</info added on 2025-07-07T05:55:31.685Z>",
            "status": "done",
            "testStrategy": "After applying the changes, run `terraform output` on a deployed instance of the module. Verify that all new outputs are present and that their values match the deployed resource's properties in the Azure portal."
          },
          {
            "id": 2,
            "title": "Review and Update `azurerm_storage_container` Outputs",
            "description": "Review the `azurerm_storage_container` resource attributes in the Terraform documentation. Update `outputs.tf` to expose useful attributes for all created containers, likely in a map format.",
            "dependencies": [],
            "details": "1. Consult the `azurerm_storage_container` documentation on the Terraform Registry.\n2. Since containers are created dynamically (likely via `for_each`), structure the output as a map keyed by the container name.\n3. The output map should expose key attributes for each container, such as `id`, `name`, and `resource_manager_id`.\n4. Implement the output like this: `output \"containers\" { description = \"A map of storage containers.\" value = { for k, v in azurerm_storage_container.this : k => { id = v.id, name = v.name, resource_manager_id = v.resource_manager_id } } }`.\n5. Ensure the output is created conditionally if container creation is optional.\n<info added on 2025-07-07T05:55:52.315Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). When using Context7 or researching documentation, follow section 1: MCP Tools Usage Rules. Key principles to apply: Edit only outputs.tf, use proper map outputs for dynamic resources, and add clear descriptions.\n</info added on 2025-07-07T05:55:52.315Z>",
            "status": "done",
            "testStrategy": "Deploy an example that creates multiple storage containers. Run `terraform output containers` and validate that the output is a map containing the correct details for each container."
          },
          {
            "id": 3,
            "title": "Review and Update `azurerm_storage_queue` Outputs",
            "description": "Review the `azurerm_storage_queue` resource attributes in the Terraform documentation. Update `outputs.tf` to expose useful attributes for all created queues, likely in a map format.",
            "dependencies": [],
            "details": "1. Check the `azurerm_storage_queue` documentation on the Terraform Registry.\n2. Queues are likely created via `for_each`, so the output should be a map keyed by the queue name.\n3. The output map should expose key attributes for each queue, such as `id`, `name`, and `resource_manager_id`.\n4. Implement the output like this: `output \"queues\" { description = \"A map of storage queues.\" value = { for k, v in azurerm_storage_queue.this : k => { id = v.id, name = v.name, resource_manager_id = v.resource_manager_id } } }`.\n5. Ensure the output is created conditionally if queue creation is optional.\n<info added on 2025-07-07T05:56:13.198Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Edit only outputs.tf, use map outputs for collections of resources, ensure conditional outputs when resources are optional.\n</info added on 2025-07-07T05:56:13.198Z>",
            "status": "done",
            "testStrategy": "Deploy an example that creates multiple storage queues. Run `terraform output queues` and validate that the output is a map containing the correct details for each queue."
          },
          {
            "id": 4,
            "title": "Review and Update `azurerm_storage_share` Outputs",
            "description": "Review the `azurerm_storage_share` resource attributes in the Terraform documentation. Update `outputs.tf` to expose useful attributes for all created file shares, likely in a map format.",
            "dependencies": [],
            "details": "1. Refer to the `azurerm_storage_share` documentation on the Terraform Registry.\n2. File shares are likely created via `for_each`, so the output should be a map keyed by the share name.\n3. The output map should expose key attributes for each share, such as `id`, `name`, `resource_manager_id`, and `url`.\n4. Implement the output like this: `output \"file_shares\" { description = \"A map of storage file shares.\" value = { for k, v in azurerm_storage_share.this : k => { id = v.id, name = v.name, url = v.url } } }`.\n5. Ensure the output is created conditionally if file share creation is optional.\n<info added on 2025-07-07T05:56:34.710Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Edit only outputs.tf, use map outputs for collections, include all relevant attributes like url for file shares.\n</info added on 2025-07-07T05:56:34.710Z>",
            "status": "done",
            "testStrategy": "Deploy an example that creates multiple file shares. Run `terraform output file_shares` and validate that the output is a map containing the correct details for each share."
          },
          {
            "id": 5,
            "title": "Review and Update `azurerm_storage_table` Outputs",
            "description": "Review the `azurerm_storage_table` resource attributes in the Terraform documentation. Update `outputs.tf` to expose useful attributes for all created tables, likely in a map format.",
            "dependencies": [],
            "details": "1. Look up the `azurerm_storage_table` documentation on the Terraform Registry.\n2. Tables are likely created via `for_each`, so the output should be a map keyed by the table name.\n3. The output map should expose key attributes for each table, such as `id`, `name`, and `resource_manager_id`.\n4. Implement the output like this: `output \"tables\" { description = \"A map of storage tables.\" value = { for k, v in azurerm_storage_table.this : k => { id = v.id, name = v.name, resource_manager_id = v.resource_manager_id } } }`.\n5. Ensure the output is created conditionally if table creation is optional.\n<info added on 2025-07-07T05:56:56.741Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to follow: Edit only outputs.tf, follow existing patterns in the module, and ensure conditional outputs for optional resources.\n</info added on 2025-07-07T05:56:56.741Z>",
            "status": "done",
            "testStrategy": "Deploy an example that creates multiple storage tables. Run `terraform output tables` and validate that the output is a map containing the correct details for each table."
          },
          {
            "id": 6,
            "title": "Review and Update `azurerm_private_endpoint` Outputs",
            "description": "Review the `azurerm_private_endpoint` resource attributes in the Terraform documentation. Update `outputs.tf` to expose connection details for any private endpoints associated with the storage account.",
            "dependencies": [],
            "details": "1. Examine the `azurerm_private_endpoint` documentation on the Terraform Registry.\n2. The module may create multiple private endpoints (for blob, file, etc.), so structure the output as a map keyed by the sub-resource type (e.g., 'blob').\n3. Expose key attributes like `id`, `name`, and `private_ip_address` (found within the `private_service_connection` block).\n4. Implement the output like this: `output \"private_endpoints\" { description = \"A map of private endpoints.\" value = { for k, v in azurerm_private_endpoint.this : k => { id = v.id, name = v.name, private_ip_address = v.private_service_connection[0].private_ip_address } } }`.\n5. Ensure the output is created conditionally.\n<info added on 2025-07-07T05:57:13.209Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to follow: Edit only the outputs.tf file, expose private endpoint connection details including private IP addresses, and use a map structure for multiple endpoints.\n</info added on 2025-07-07T05:57:13.209Z>",
            "status": "done",
            "testStrategy": "Deploy an example that creates a private endpoint for the blob service. Run `terraform output private_endpoints` and verify the map contains the correct ID, name, and private IP address."
          },
          {
            "id": 7,
            "title": "Review and Update `azurerm_storage_account_queue_properties` Outputs",
            "description": "Review the `azurerm_storage_account_queue_properties` resource in the Terraform documentation. Update `outputs.tf` to expose its ID if it provides value.",
            "dependencies": [],
            "details": "1. Check the `azurerm_storage_account_queue_properties` documentation on the Terraform Registry.\n2. This resource primarily configures settings and may only export its `id`.\n3. Determine if outputting the resource ID is useful for consumers of the module.\n4. If so, add a new output: `output \"queue_properties_id\" { description = \"The resource ID of the storage account queue properties.\" value = one(azurerm_storage_account_queue_properties.this[*].id) }`.\n5. Use a conditional expression to handle cases where the resource is not created.\n<info added on 2025-07-07T05:57:32.863Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Edit only outputs.tf, use one() function for single optional resources, determine if resource ID output provides value to module consumers.\n</info added on 2025-07-07T05:57:32.863Z>",
            "status": "done",
            "testStrategy": "Deploy an example where queue properties are configured. Run `terraform output queue_properties_id` and verify it returns the correct resource ID. Ensure it returns null when not configured."
          },
          {
            "id": 8,
            "title": "Review and Update `azurerm_storage_account_static_website` Outputs",
            "description": "Review the `azurerm_storage_account_static_website` resource in the Terraform documentation. Ensure that related outputs on the main storage account resource are correctly exposed.",
            "dependencies": [],
            "details": "1. Check the `azurerm_storage_account_static_website` documentation.\n2. This resource enables static website hosting, but the primary endpoints (`primary_web_endpoint`, `primary_web_host`) are attributes of the `azurerm_storage_account` resource itself.\n3. This task is to double-check that the outputs for `primary_web_endpoint` and `primary_web_host` are correctly implemented in `outputs.tf` as part of the `azurerm_storage_account` review.\n4. Consider adding an output for the `azurerm_storage_account_static_website` resource `id` for completeness: `output \"static_website_id\" { ... }`.\n<info added on 2025-07-07T05:57:55.602Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to apply: Edit only outputs.tf and verify that the primary_web_endpoint and primary_web_host outputs exist in the azurerm_storage_account outputs section.\n</info added on 2025-07-07T05:57:55.602Z>",
            "status": "done",
            "testStrategy": "Deploy an example with static website hosting enabled. Run `terraform output` and verify that `primary_web_endpoint` and `primary_web_host` are populated with the correct URLs."
          },
          {
            "id": 9,
            "title": "Review and Update `azurerm_storage_management_policy` Outputs",
            "description": "Review the `azurerm_storage_management_policy` resource in the Terraform documentation. Update `outputs.tf` to expose its resource ID.",
            "dependencies": [],
            "details": "1. Consult the `azurerm_storage_management_policy` documentation on the Terraform Registry.\n2. The main exported attribute is the resource `id`.\n3. Add an output to expose this ID, which is useful for auditing or creating dependencies.\n4. Implement the output: `output \"storage_management_policy_id\" { description = \"The resource ID of the storage management policy.\" value = one(azurerm_storage_management_policy.this[*].id) }`.\n5. Use a conditional expression to handle cases where the resource is not created.\n<info added on 2025-07-07T05:58:14.964Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Edit only outputs.tf, use one() function for single optional resources, expose resource IDs for auditing purposes.\n</info added on 2025-07-07T05:58:14.964Z>",
            "status": "done",
            "testStrategy": "Deploy an example with a storage management policy. Run `terraform output storage_management_policy_id` and verify it returns the correct resource ID. Ensure it returns null when no policy is configured."
          },
          {
            "id": 10,
            "title": "Review and Update `azurerm_monitor_diagnostic_setting` Outputs",
            "description": "Review the `azurerm_monitor_diagnostic_setting` resource in the Terraform documentation. Update `outputs.tf` to expose details of the configured diagnostic settings.",
            "dependencies": [],
            "details": "1. Check the `azurerm_monitor_diagnostic_setting` documentation on the Terraform Registry.\n2. The module may create multiple diagnostic settings, so the output should be a map, keyed by the setting's name or a logical key.\n3. The output map should expose the `id` and `name` of each diagnostic setting.\n4. Implement the output: `output \"diagnostic_settings\" { description = \"A map of diagnostic settings applied to the storage account.\" value = { for k, v in azurerm_monitor_diagnostic_setting.this : k => { id = v.id, name = v.name } } }`.\n5. Ensure the output is created conditionally.\n<info added on 2025-07-07T05:58:34.805Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Edit only outputs.tf, use map outputs for multiple diagnostic settings, ensure conditional outputs for optional resources.\n</info added on 2025-07-07T05:58:34.805Z>",
            "status": "done",
            "testStrategy": "Deploy an example with one or more diagnostic settings configured. Run `terraform output diagnostic_settings` and validate that the output is a map containing the correct ID and name for each setting."
          }
        ]
      },
      {
        "id": 20,
        "title": "Update and Expand Storage Account Module Examples",
        "description": "Update the five existing azurerm_storage_account module examples and create two new ones (data-lake-gen2, advanced-policies) to demonstrate the new features, parameters, and outputs introduced in tasks #18 and #19. Ensure all examples have updated READMEs and follow best practices.",
        "details": "This task involves a comprehensive overhaul of the storage account module's examples. For all 7 examples, ensure prerequisite resources like resource groups are defined within the example's Terraform configuration. Update README.md files to reflect the changes and intended use case. Where applicable, demonstrate access patterns using Microsoft Entra ID roles instead of keys. \n1. **Update `simple` example**: Keep it minimal but explicitly set `shared_access_key_enabled = true` to showcase this control. \n2. **Update `complete` example**: Integrate a wide range of new parameters from Task #18, such as `default_to_oauth_authentication`, and reference the new module outputs from Task #19. \n3. **Update `secure` and `secure-private-endpoint` examples**: Enhance with new security parameters like `allowed_copy_scope` and `min_tls_version`. \n4. **Update `multi-region` example**: Verify geo-redundancy settings and incorporate `cross_tenant_replication_enabled`. \n5. **Create new `data-lake-gen2` example**: This example must set `is_hns_enabled = true` and demonstrate the configuration of `sftp_enabled` and `nfsv3_enabled`. \n6. **Create new `advanced-policies` example**: This example should showcase the new complex object variables for `sas_policy` and `immutability_policy`, and also configure features like `routing_preference` and `custom_domain`.",
        "testStrategy": "For each of the 7 examples (5 updated, 2 new), perform the following steps: \n1. Navigate to the example's directory (e.g., `examples/storage_account/data-lake-gen2`). \n2. Run `terraform init` and `terraform apply` to deploy the resources. Verify the deployment completes successfully without errors. \n3. For each example, perform a spot-check in the Azure Portal to confirm the specific features are configured as expected. For instance, check that SFTP is enabled for the `data-lake-gen2` example and that the SAS policy is applied for the `advanced-policies` example. \n4. Review the generated `README.md` for each example to ensure it is clear, accurate, and reflects the configuration. \n5. Run `terraform destroy` for each example and verify that all created resources are removed cleanly.",
        "status": "pending",
        "dependencies": [
          6,
          18,
          19
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update `simple` Storage Account Example",
            "description": "Update the `simple` example to be a minimal, functional demonstration of the module. It should explicitly set `shared_access_key_enabled = true` and include basic container, queue, table, and share resources to confirm functionality.",
            "dependencies": [],
            "details": "In `examples/simple/main.tf`, ensure an `azurerm_resource_group` is defined locally for the example to be self-contained. In the module call, explicitly set `shared_access_key_enabled = true`. Add `azurerm_storage_container`, `azurerm_storage_queue`, `azurerm_storage_table`, and `azurerm_storage_share` resources that use the storage account name from the module's output. Update `outputs.tf` to expose essential resource IDs and endpoints. Refresh the `README.md` to reflect these changes and the example's purpose.\n<info added on 2025-07-07T06:23:09.083Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to apply: Keep simple example minimal but functional, ensure shared_access_key_enabled=true for user access, and use resource blocks for prerequisites. Document your observations and what you implemented in the subtask notes.\n</info added on 2025-07-07T06:23:09.083Z>",
            "status": "done",
            "testStrategy": "Run `terraform apply` on the example directory. Verify the storage account is created with the shared access key enabled in the Azure Portal. Confirm the container, queue, table, and share are also created."
          },
          {
            "id": 2,
            "title": "Update `complete` Storage Account Example",
            "description": "Overhaul the `complete` example to serve as a comprehensive showcase of the module's capabilities, integrating a wide range of new parameters from Task #18 and referencing new outputs from Task #19.",
            "dependencies": [],
            "details": "In `examples/complete/main.tf`, expand the module block to include new parameters such as `default_to_oauth_authentication`, advanced blob properties (versioning, change feed, last access time), and detailed network rules. Update the `outputs.tf` file to expose all new module outputs introduced in Task #19. Thoroughly document each configured parameter and its purpose in the `README.md`.\n<info added on 2025-07-07T06:23:38.224Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9), and section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Showcase comprehensive features from task #18, use all new outputs from task #19, document each parameter's purpose. Use resource blocks for prerequisites. Document your observations and implementation notes.\n</info added on 2025-07-07T06:23:38.224Z>",
            "status": "done",
            "testStrategy": "Run `terraform plan` to verify all new parameters are correctly passed. Run `terraform apply` and inspect the created storage account in the Azure Portal to confirm that all settings (e.g., blob versioning, network rules) have been applied as configured."
          },
          {
            "id": 3,
            "title": "Update `secure` Storage Account Example",
            "description": "Enhance the `secure` example with new security-focused parameters. This example should demonstrate a secure-by-default configuration using features like OAuth-only authentication, minimum TLS version, and copy scope restrictions.",
            "dependencies": [],
            "details": "Modify `examples/secure/main.tf` to set `default_to_oauth_authentication = true`, `min_tls_version = \"TLS1_2\"`, and `allowed_copy_scope = \"PrivateLink\"`. Ensure `public_network_access_enabled` is explicitly set to `false` or restricted via firewall rules. Update the `README.md` to explain the security posture achieved by these settings.\n<info added on 2025-07-07T06:23:53.222Z>\nMANDATORY: Before starting this subtask, you must review CLAUDE.md, specifically the 'important-instruction-reminders' (lines 5-9) and 'section 9: Terraform Best Practices Guide' (lines 112-122). Key principles to focus on are security parameters, demonstrating OAuth authentication, minimum TLS, and copy scope restrictions. Document the security posture achieved and include any observations and notes.\n</info added on 2025-07-07T06:23:53.222Z>",
            "status": "done",
            "testStrategy": "Apply the configuration and verify in the Azure Portal that 'Default to Microsoft Entra authorization' is enabled, the minimum TLS version is 1.2, and public access is disabled. Attempting to generate a SAS key should fail if shared key access is disabled."
          },
          {
            "id": 4,
            "title": "Update `secure-private-endpoint` Storage Account Example",
            "description": "Update the `secure-private-endpoint` example to demonstrate secure access over a private network, including the creation of prerequisite networking resources and private DNS integration.",
            "dependencies": [],
            "details": "Within the `examples/secure-private-endpoint/` directory, define all necessary prerequisite resources in `main.tf`: `azurerm_resource_group`, `azurerm_virtual_network`, `azurerm_subnet`, and `azurerm_private_dns_zone`. Configure the module to create a private endpoint for the `blob` sub-resource and associate it with the private DNS zone. Ensure `public_network_access_enabled = false`. Update the `README.md` with a clear explanation of the architecture.\n<info added on 2025-07-07T06:24:13.192Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Create complete networking prerequisites, demonstrate private endpoint with DNS integration, disable public access. Document architecture clearly. Include observations.\n</info added on 2025-07-07T06:24:13.192Z>",
            "status": "done",
            "testStrategy": "Deploy the example. From a VM within the configured VNet, use `nslookup` to verify the storage account's FQDN resolves to a private IP address. Confirm that access from the public internet is blocked."
          },
          {
            "id": 5,
            "title": "Update `multi-region` Storage Account Example",
            "description": "Update the `multi-region` example to correctly configure geo-redundant storage (GRS/GZRS) and demonstrate the `cross_tenant_replication_enabled` parameter, showcasing disaster recovery and data residency features.",
            "dependencies": [],
            "details": "In `examples/multi-region/main.tf`, set the `account_replication_type` to `GRS` or `GZRS`. Set the `cross_tenant_replication_enabled` parameter to `true`. Update `outputs.tf` to show the primary and secondary location and endpoint URLs from the module's outputs. Update the `README.md` to explain the geo-replication and cross-tenant replication use cases.\n<info added on 2025-07-07T06:24:34.076Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Configure geo-redundancy correctly, showcase cross-tenant replication, display primary and secondary endpoints. Document disaster recovery use cases. Include observations.\n</info added on 2025-07-07T06:24:34.076Z>",
            "status": "done",
            "testStrategy": "Apply the configuration and verify in the Azure Portal that the storage account's replication is set to GRS/GZRS. Check the 'Geo-replication' blade to confirm the secondary location. The `cross_tenant_replication_enabled` property can be verified using Azure CLI or PowerShell."
          },
          {
            "id": 6,
            "title": "Create New `data-lake-gen2` Example",
            "description": "Create a new example for a Data Lake Storage Gen2 account. This example must enable the hierarchical namespace (`is_hns_enabled = true`) and demonstrate the configuration of SFTP and NFSv3.",
            "dependencies": [],
            "details": "Create a new directory `examples/data-lake-gen2/`. In a new `main.tf`, call the module with `is_hns_enabled = true`, `sftp_enabled = true`, and `nfsv3_enabled = true`. The configuration should also include creating a container and setting up a local user for SFTP access. Create a `README.md` explaining the setup for a data lake and how to connect via SFTP/NFSv3. Add a corresponding `outputs.tf`.\n<info added on 2025-07-07T06:25:00.185Z>\nBefore starting this subtask, MANDATORY review CLAUDE.md sections: important-instruction-reminders (lines 5-9), section 9: Terraform Best Practices Guide (lines 112-122). Key principles: Create new example directory, enable HNS/SFTP/NFSv3, setup local user for SFTP, document data lake architecture. Create comprehensive README. Include observations and implementation notes.\n</info added on 2025-07-07T06:25:00.185Z>",
            "status": "done",
            "testStrategy": "Deploy the example. Verify in the Azure Portal that 'Hierarchical namespace' is enabled. Use an SFTP client to connect to the storage account using the configured local user credentials. Verify NFSv3 mount works from a supported client."
          },
          {
            "id": 7,
            "title": "Create New `advanced-policies` Example",
            "description": "Create a new example showcasing advanced policy configurations. This includes setting a `sas_policy`, an `immutability_policy` for a container, and configuring `routing_preference` and a `custom_domain`.",
            "dependencies": [],
            "details": "Create a new directory `examples/advanced-policies/`. In `main.tf`, define complex local variables for `sas_policy` (e.g., setting expiration period) and `immutability_policy` (e.g., for a specific container). Pass these to the module. Also configure `routing_preference = \"InternetRouting\"` and set up a `custom_domain`. The `README.md` must document the manual CNAME record prerequisite for the custom domain to work.\n<info added on 2025-07-07T06:25:22.100Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Include observations and notes.\n</info added on 2025-07-07T06:25:22.100Z>",
            "status": "done",
            "testStrategy": "Deploy the example. Verify the SAS policy is applied by trying to create a SAS token that violates the policy. Check the container's immutability policy in the portal. Verify the routing preference is set to 'Internet routing'. Test the custom domain after configuring the CNAME record manually."
          },
          {
            "id": 8,
            "title": "Create New `identity-access` Example",
            "description": "Create a new example focused on identity-based access. Demonstrate enabling a system-assigned managed identity and assigning an RBAC role (e.g., 'Storage Blob Data Contributor') to a principal for keyless access.",
            "dependencies": [],
            "details": "Create a new directory `examples/identity-access/`. In `main.tf`, configure the module to enable a system-assigned identity. Use a separate `azurerm_role_assignment` resource to grant the 'Storage Blob Data Reader' role to a principal (e.g., using a data source for the current client config) scoped to the storage account. Set `default_to_oauth_authentication = true` and `shared_access_key_enabled = false`. The `README.md` must explain the benefits and process of keyless authentication.\n<info added on 2025-07-07T06:25:38.925Z>\nMANDATORY: Before starting this subtask, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to apply are: create a new example directory, enable system-assigned identity, demonstrate RBAC assignments, disable shared keys, and show Microsoft Entra ID authentication benefits. Include observations.\n</info added on 2025-07-07T06:25:38.925Z>",
            "status": "done",
            "testStrategy": "Deploy the example. Using Azure CLI with credentials matching the assigned principal, attempt to read a blob from a container using an `--auth-mode login` command. The command should succeed. Attempting to list keys should fail."
          },
          {
            "id": 9,
            "title": "Update Test Scripts and Root Documentation",
            "description": "Integrate the three new examples (`data-lake-gen2`, `advanced-policies`, `identity-access`) into the automated testing script (`test-examples.sh`). Update the root-level README to list and briefly describe all available examples.",
            "dependencies": [],
            "details": "Modify the `test-examples.sh` script (or equivalent testing framework) to add `terraform init`, `plan`, `apply`, and `destroy` stages for the `data-lake-gen2`, `advanced-policies`, and `identity-access` example directories. Update the main `README.md` file in the module's root directory, ensuring the table or list of examples includes the new additions with brief descriptions.\n<info added on 2025-07-07T06:25:53.190Z>\nMANDATORY: Before starting, review CLAUDE.md sections: important-instruction-reminders (lines 5-9) and section 9: Terraform Best Practices Guide (lines 112-122). Key principles to follow: Update test scripts to include new examples, update the root README with all examples, and ensure all tests pass. Document the testing approach and include any observations.\n</info added on 2025-07-07T06:25:53.190Z>",
            "status": "done",
            "testStrategy": "Run the modified `test-examples.sh` script locally or in a CI environment. Verify that the script executes successfully for all examples, including the newly added ones, without any errors during the plan, apply, or destroy phases."
          }
        ]
      },
      {
        "id": 21,
        "title": "Parallel Validation of All Storage Account Module Examples",
        "description": "Create a testing workflow to run `terraform init` and `terraform validate` in parallel across all storage account module examples. This task ensures all examples are syntactically correct and have their provider dependencies properly configured.",
        "details": "Implement a GitHub Actions workflow that validates all 8 examples for the storage account module. The workflow should use a matrix strategy to run a separate, parallel job for each example directory. Each job must perform the following steps: 1. Check out the repository code. 2. Set up the specified version of Terraform. 3. Configure Azure credentials to allow the provider to initialize correctly. 4. Navigate into the specific example's directory (e.g., `examples/storage_account/simple`). 5. Execute `terraform init -backend=false` to initialize the provider and modules without configuring a state backend. 6. Execute `terraform validate` to check for syntax and configuration errors. Any validation errors discovered during implementation must be fixed. This includes correcting syntax, addressing provider version constraints, or fixing variable definitions within the example configurations. All fixes must adhere to the project's coding standards.",
        "testStrategy": "1. Trigger the newly created GitHub Actions workflow by pushing a commit or creating a pull request. 2. Navigate to the 'Actions' tab in the GitHub repository and observe the workflow run. 3. Verify that a parallel job is initiated for each of the 8 storage account examples. 4. Confirm that each job successfully completes the `terraform init` and `terraform validate` steps with a green checkmark. 5. To ensure the failure condition works, intentionally introduce a syntax error into one of the example's `main.tf` files, push the change, and verify that the corresponding job in the workflow fails as expected.",
        "status": "pending",
        "dependencies": [
          20
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Validate and Fix the 'simple' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/simple` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/simple` directory.\n2. Open the provider configuration file (e.g., `main.tf` or `provider.tf`).\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block. Ensure a corresponding variable is defined in `variables.tf`.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, analyze the error and correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 2,
            "title": "Validate and Fix the 'complete' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/complete` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/complete` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 3,
            "title": "Validate and Fix the 'secure' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/secure` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/secure` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 4,
            "title": "Validate and Fix the 'secure-private-endpoint' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/secure-private-endpoint` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/secure-private-endpoint` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 5,
            "title": "Validate and Fix the 'multi-region' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/multi-region` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/multi-region` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 6,
            "title": "Validate and Fix the 'data-lake-gen2' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/data-lake-gen2` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/data-lake-gen2` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 7,
            "title": "Validate and Fix the 'advanced-policies' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/advanced-policies` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/advanced-policies` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          },
          {
            "id": 8,
            "title": "Validate and Fix the 'identity-access' Storage Account Example",
            "description": "Update the Terraform provider block in the `examples/storage_account/identity-access` directory to include the `subscription_id`. Run `terraform init` and `terraform validate` to ensure the configuration is valid. Fix any syntax or configuration errors that arise.",
            "dependencies": [],
            "details": "1. Navigate to the `examples/storage_account/identity-access` directory.\n2. Open the provider configuration file.\n3. Add `subscription_id = var.subscription_id` to the `azurerm` provider block and define the variable if it doesn't exist.\n4. From this directory, execute `terraform init -backend=false`.\n5. Execute `terraform validate`.\n6. If validation fails, correct the Terraform configuration files in this directory. Commit the fixes.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` locally. The command should exit with code 0 and produce no error output. The changes will also be validated by the parent task's GitHub Actions workflow once implemented."
          }
        ]
      },
      {
        "id": 22,
        "title": "Enhance Storage Account Module with Security and Blob Properties",
        "description": "This task involves updating the azurerm_storage_account module to add new security and blob storage parameters, fix the azure_files_authentication implementation, and update relevant examples to reflect these changes.",
        "details": "1. Add `public_network_access_enabled`: In `variables.tf`, add a new boolean variable `public_network_access_enabled` with a default of `false`. In `main.tf`, add the `public_network_access_enabled = var.public_network_access_enabled` argument to the `azurerm_storage_account` resource.\n2. Fix `azure_files_authentication`: In `main.tf`, implement a `dynamic \"azure_files_authentication\"` block for the `azurerm_storage_account` resource. The `for_each` should be `var.azure_files_authentication != null ? [var.azure_files_authentication] : []` to correctly process the existing complex object variable and enable the feature when the variable is not null.\n3. Extend `blob_properties`: In `variables.tf`, update the `blob_properties` variable object to include `change_feed_retention_in_days` (type `number`, default `null`) and an optional `restore_policy` object containing a `days` attribute (type `number`). In `main.tf`, update the `blob_properties` block to pass these new values, using a dynamic block for the `restore_policy` if necessary to handle its optional nature.\n4. Update Examples: Modify `examples/storage_account/secure/main.tf` to explicitly set `public_network_access_enabled = false`. Update `examples/storage_account/complete/main.tf` to demonstrate the usage of `azure_files_authentication`, `change_feed_retention_in_days`, and `restore_policy` with sample values.",
        "testStrategy": "1. **Public Access Validation**: Run `terraform apply` on the updated `secure` example. Using the Azure Portal or CLI, verify that the deployed storage account has 'Public network access' set to 'Disabled'.\n2. **Azure Files Auth Validation**: Deploy the `complete` example. In the Azure Portal, navigate to the storage account's 'Configuration' settings and confirm that Azure Files identity-based access for the specified directory service is enabled.\n3. **Blob Properties Validation**: After deploying the `complete` example, inspect the storage account's 'Data protection' settings in the Azure Portal. Verify that 'Point-in-time restore for blobs' is enabled with the correct retention period and that 'Blob change feed' retention is configured as specified.\n4. **Syntax Validation**: Run `terraform init` and `terraform validate` on both the `secure` and `complete` example directories to ensure the changes are syntactically correct and pass provider validation. This should be integrated with the workflow from Task #21.",
        "status": "done",
        "dependencies": [
          18,
          20,
          21
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "General Project Cleanup and Standardization",
        "description": "Apply general fixes across all examples, including removing committed terraform.tfstate files, adding a proper .gitignore file, removing hardcoded subscription IDs, and ensuring all examples adhere to the best practices outlined in CLAUDE.md and TERRAFORM_BEST_PRACTISES_GUIDE.md.",
        "details": "1. Create a root `.gitignore` file containing at least `*.tfstate`, `*.tfstate.*`, `.terraform/`, and `*.tfvars`. 2. Execute `git rm --cached **/*.tfstate` to unstage any committed state files from the repository. 3. Systematically review all `.tf` files within the examples directories and remove any hardcoded `subscription_id` attributes from provider blocks. 4. Perform a comprehensive review of each example against the project's Terraform and general contribution guidelines.",
        "testStrategy": "Verify the successful removal of state files by running `git status` and ensuring no `.tfstate` files are tracked. Run `terraform validate` in each example directory to check for syntax errors. Manually inspect the codebase for the absence of hardcoded subscription IDs and for compliance with documented best practices.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create and Commit Root .gitignore File",
            "description": "Create a comprehensive .gitignore file at the root of the project to prevent committing sensitive or unnecessary files, such as Terraform state files, local variables, and temporary directories.",
            "dependencies": [],
            "details": "Create a new file named `.gitignore` in the project's root directory. Add entries to ignore common Terraform artifacts and local configuration. The file should include at least the following patterns:\n\n# Terraform\n*.tfstate\n*.tfstate.*\n.terraform/\n*.tfvars\ncrash.log\n\n# General\n.DS_Store\n*~",
            "status": "pending",
            "testStrategy": "Verify that after creating the .gitignore file, running `git status` does not show any `.tfstate` or `.terraform` directories as untracked files if they exist locally. Attempt to add a `test.tfstate` file to staging (`git add test.tfstate`) and confirm that Git ignores it."
          },
          {
            "id": 2,
            "title": "Remove All Committed Terraform State Files from Git History",
            "description": "Identify and remove any `terraform.tfstate` or `terraform.tfstate.backup` files that have been previously committed to the repository. This ensures that sensitive state information is removed from the Git history.",
            "dependencies": [
              1
            ],
            "details": "Execute the command `git rm --cached '**/*.tfstate'` from the root of the repository. This will unstage all files matching the pattern `*.tfstate` from the Git index across all directories. Repeat the command for `*.tfstate.*` if any backup files are present: `git rm --cached '**/*.tfstate.*'`. After running the commands, commit the changes with a clear message like 'chore: Remove tracked terraform state files'.",
            "status": "pending",
            "testStrategy": "After committing the changes, run `git ls-files | grep '.tfstate'` to confirm that no state files are being tracked by Git. Clone the repository to a new directory and verify that no `.tfstate` files are present."
          },
          {
            "id": 3,
            "title": "Remove Hardcoded Subscription IDs from Provider Blocks",
            "description": "Systematically review all `.tf` files within the storage account examples and remove any hardcoded `subscription_id` attributes from the `azurerm` provider blocks. This promotes better configuration management and avoids security risks.",
            "dependencies": [
              2
            ],
            "details": "Search across all `*.tf` files in the `examples/` directory for the string `subscription_id`. For each occurrence within a provider block (e.g., `provider \"azurerm\" { ... }`), delete the line containing `subscription_id`. The provider should be configured via environment variables (e.g., `ARM_SUBSCRIPTION_ID`) or other secure means, not hardcoded values.",
            "status": "pending",
            "testStrategy": "Perform a global search for `subscription_id` within the project's `.tf` files. The search should return no results within any `provider \"azurerm\"` blocks. Manually inspect the `main.tf` or `provider.tf` file in each example directory to confirm the removal."
          },
          {
            "id": 4,
            "title": "Align Examples with CLAUDE.md Contribution Guidelines",
            "description": "Review each storage account example to ensure it adheres to the principles outlined in `CLAUDE.md`. Specifically, ensure that examples do not create resources that the module itself is designed to provide (e.g., resource groups, if the module has an option to create one).",
            "dependencies": [
              3
            ],
            "details": "For each example directory, review the Terraform configuration (`.tf` files). Compare the resources being created in the example with the functionality of the module being called. If the module has an input variable like `create_resource_group = true`, the example should leverage that instead of defining a separate `resource \"azurerm_resource_group\" \"example\" { ... }`. Refactor any such examples to use the module's built-in capabilities.",
            "status": "pending",
            "testStrategy": "For each example, run `terraform plan`. The plan should show that the resources being created are appropriate for an example demonstrating the module's usage, and not redundant resources that the module itself manages. The diff for this subtask should only contain removals of redundant resource blocks from the examples."
          },
          {
            "id": 5,
            "title": "Ensure Adherence to TERRAFORM_BEST_PRACTISES_GUIDE.md",
            "description": "Perform a final, comprehensive review of all storage account examples to ensure they comply with the project's Terraform best practices guide. This includes checking for proper variable definitions, outputs, naming conventions, and module sourcing.",
            "dependencies": [
              4
            ],
            "details": "Review each example against the checklist in `TERRAFORM_BEST_PRACTISES_GUIDE.md`. Key items to check include:\n1. All variables used in `main.tf` are defined in `variables.tf` with types and descriptions.\n2. Important resource attributes are exposed via `outputs.tf`.\n3. Module source points to the local path (`../../`) for development purposes.\n4. Resource and variable names follow the project's naming conventions. \nRefactor the code in each example to meet these standards.",
            "status": "pending",
            "testStrategy": "Manually review the code changes against the `TERRAFORM_BEST_PRACTISES_GUIDE.md` document. Run `terraform validate` in each example directory to catch syntax errors. The code should be clean, well-documented, and consistent across all examples."
          }
        ]
      },
      {
        "id": 24,
        "title": "Refactor 'Simple' and 'Complete' Examples",
        "description": "Update the 'simple' and 'complete' examples to align with best practices, including renaming the 'simple' directory to 'basic', adding variables for configuration, improving security defaults, and ensuring the module's capabilities are used correctly.",
        "details": "For the 'simple' example: 1. Rename the directory from `simple` to `basic`. 2. Remove the `shared_access_key_enabled = true` setting or add a prominent comment warning about the security implications. 3. Introduce a `variables.tf` file for `location` and `resource_group_name`. 4. Use the module's `containers` input to create at least one storage container, e.g., `containers = { \"logs\" = { access_type = \"private\" } }`. For the 'complete' example: 1. Set `network_rules_default_action = \"Deny\"` in the module block. 2. Add a `variables.tf` file for `location`, `prefix`, and `network_ranges`.",
        "testStrategy": "For each modified example, run `terraform plan` and `terraform apply`. In the Azure Portal, confirm that the 'basic' example's storage account contains the new container. For the 'complete' example, verify that the storage account's networking configuration has its default action set to 'Deny'.",
        "priority": "medium",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Rename 'simple' example to 'basic' and add variables.tf",
            "description": "Rename the `examples/simple` directory to `examples/basic`. Create a `variables.tf` file within this new directory to define variables for `location` and `resource_group_name`. Update the `main.tf` to use these new variables and provide an example `terraform.tfvars` file.",
            "dependencies": [],
            "details": "1. Rename the directory: `git mv examples/simple examples/basic`. 2. Create `examples/basic/variables.tf` with variables for `location` and `resource_group_name`. 3. In `examples/basic/main.tf`, replace the hardcoded values for these attributes with `var.location` and `var.resource_group_name`. 4. Create an `examples/basic/terraform.tfvars.example` file to demonstrate how to populate these variables.",
            "status": "pending",
            "testStrategy": "Navigate to the `examples/basic` directory. Run `terraform init` and `terraform validate` to ensure the configuration is syntactically correct. Run `terraform plan` with appropriate variable values to confirm the changes are correctly interpreted."
          },
          {
            "id": 2,
            "title": "Improve Security and Add Container Creation to 'basic' Example",
            "description": "In the `examples/basic/main.tf`, remove the `shared_access_key_enabled = true` setting to default to a more secure configuration. Also, demonstrate the module's capability by using the `containers` input to create a private 'logs' container.",
            "dependencies": [],
            "details": "1. Edit `examples/basic/main.tf`. 2. Remove the line `shared_access_key_enabled = true` from the module block. If it doesn't exist, ensure it's not added. 3. Add the input `containers = { \"logs\" = { access_type = \"private\" } }` to the module block to demonstrate container creation.",
            "status": "pending",
            "testStrategy": "Navigate to the `examples/basic` directory. Run `terraform plan`. The plan should show the storage account being created with shared access key disabled and one storage container named 'logs' being created."
          },
          {
            "id": 3,
            "title": "Add variables.tf for the 'complete' Example",
            "description": "Create a `variables.tf` file in the `examples/complete` directory. Define variables for `location`, `prefix`, and `network_ranges` to make the example more configurable. Update the `main.tf` to use these new variables and provide an example `terraform.tfvars` file.",
            "dependencies": [],
            "details": "1. Create `examples/complete/variables.tf`. 2. Define variables: `variable \"location\" {}`, `variable \"prefix\" {}`, and `variable \"network_ranges\" { type = list(string) }`. 3. In `examples/complete/main.tf`, replace the corresponding hardcoded values with `var.location`, `var.prefix`, and `var.network_ranges`. 4. Create an `examples/complete/terraform.tfvars.example` file to demonstrate usage.",
            "status": "pending",
            "testStrategy": "Navigate to the `examples/complete` directory. Run `terraform init` and `terraform validate`. Run `terraform plan` with appropriate variable values to confirm the configuration is valid and uses the variables correctly."
          },
          {
            "id": 4,
            "title": "Harden Network Security in 'complete' Example",
            "description": "Update the `examples/complete/main.tf` to set a more secure default network rule by changing the `network_rules_default_action` to \"Deny\". This ensures that traffic is denied by default unless explicitly allowed.",
            "dependencies": [],
            "details": "1. Edit `examples/complete/main.tf`. 2. In the module block for the storage account, add or update the parameter to be `network_rules_default_action = \"Deny\"`.",
            "status": "pending",
            "testStrategy": "Navigate to the `examples/complete` directory. Run `terraform plan`. The plan should show the storage account's `network_rules` block being modified to have `default_action = \"Deny\"`."
          }
        ]
      },
      {
        "id": 25,
        "title": "Enhance 'Secure' and 'Advanced-Policies' Examples",
        "description": "Improve the 'secure' and 'advanced-policies' examples by removing inaccurate claims about Advanced Threat Protection, adding examples for immutability and SAS policies, and ensuring consistency by adding variables files and necessary warnings.",
        "details": "For the 'secure' example: 1. Remove any comments or documentation referencing 'Advanced Threat Protection'. 2. Demonstrate an immutability policy by configuring a container via the module, e.g., `containers = { \"compliance-data\" = { immutability_policy = { days_after_creation = 365, policy_mode = \"Unlocked\" } } }`. 3. Add a SAS policy configuration, e.g., `sas_policy = { expiration_period = \"01.00:00:00\", expiration_action = \"Log\" }`. For the 'advanced-policies' example: 1. Add a `variables.tf` file. 2. Add a comment in `main.tf` above the `custom_domain` block: `// WARNING: Manual DNS CNAME record creation is required for this custom domain to validate.`",
        "testStrategy": "Run `terraform plan` and `apply`. In the Azure Portal, inspect the storage account from the 'secure' example. Verify the immutability policy on the specified container and check the SAS policy settings. For the 'advanced-policies' example, confirm the warning comment is present in the code.",
        "priority": "high",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Remove Inaccurate ATP Claims from 'secure' Example",
            "description": "Update the 'secure' example by removing all comments and documentation that incorrectly reference 'Advanced Threat Protection' (ATP), as this feature is not implemented in the module.",
            "dependencies": [],
            "details": "Navigate to the `examples/secure` directory. Search through all files, particularly `main.tf` and any READMEs, for the phrases 'Advanced Threat Protection' or 'ATP'. Delete these references to clean up the example's documentation.",
            "status": "pending",
            "testStrategy": "Manually inspect the files in the `examples/secure` directory to confirm all mentions of ATP have been removed. Run `terraform validate` to ensure no syntax errors were introduced."
          },
          {
            "id": 2,
            "title": "Add Immutability and SAS Policy Examples to 'secure' Example",
            "description": "Enhance the 'secure' example by adding configuration blocks to demonstrate an immutability policy for a container and a SAS (Shared Access Signature) policy for the storage account.",
            "dependencies": [],
            "details": "In `examples/secure/main.tf`, update the module call. First, add a `sas_policy` argument to the module block, for example: `sas_policy = { expiration_period = \"01.00:00:00\", expiration_action = \"Log\" }`. Second, add a `containers` map to define a container with an immutability policy, for example: `containers = { \"compliance-data\" = { immutability_policy = { days_after_creation = 365, policy_mode = \"Unlocked\" } } }`.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` within the `examples/secure` directory. Verify that the plan output shows the storage account being configured with the specified SAS policy and a new container being created with the correct immutability policy settings."
          },
          {
            "id": 3,
            "title": "Update 'advanced-policies' Example with Variables and DNS Warning",
            "description": "Improve the 'advanced-policies' example by adding a `variables.tf` file for consistency and inserting a warning comment in `main.tf` to inform users about the manual DNS CNAME record creation required for custom domains.",
            "dependencies": [],
            "details": "1. In the `examples/advanced-policies` directory, create a new `variables.tf` file. Define variables used in `main.tf` (e.g., for resource group name, location) to align with best practices. 2. In `examples/advanced-policies/main.tf`, find the `custom_domain` block. Add the following comment on the line directly above it: `// WARNING: Manual DNS CNAME record creation is required for this custom domain to validate.`",
            "status": "pending",
            "testStrategy": "Run `terraform validate` in the `examples/advanced-policies` directory to confirm the new `variables.tf` is syntactically correct. Manually review `main.tf` to ensure the warning comment is present in the correct location."
          }
        ]
      },
      {
        "id": 26,
        "title": "Overhaul Data-Lake-Gen2 Example with ACLs and RBAC",
        "description": "Refactor the Data Lake Gen2 example to demonstrate proper Access Control List (ACL) configuration on directories and files, and to show how to assign Azure AD roles for data plane access.",
        "details": "1. Ensure the storage account is created with `is_hns_enabled = true`. 2. Use the `azurerm_storage_data_lake_gen2_path` resource to create a directory structure and apply ACLs. Example: `resource \"azurerm_storage_data_lake_gen2_path\" \"example\" { path = \"raw/data\", filesystem_name = module.storage.container_names[\"datalakefs\"], storage_account_id = module.storage.id, resource = \"directory\", ace = [{ type = \"user\", id = var.user_object_id, permissions = \"rwx\" }] }`. 3. Add `azurerm_role_assignment` resources to grant roles like 'Storage Blob Data Owner' to a principal, scoped to the storage account.",
        "testStrategy": "Apply the configuration. Use Azure CLI (`az storage fs access list`) or Azure Storage Explorer to verify that the directory structure and ACLs are set as defined. In the Azure Portal, check the 'Access control (IAM)' blade of the storage account to confirm the role assignments have been created.",
        "priority": "high",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Foundational Resources: Azure AD Principal and Data Lake Storage",
            "description": "Create the necessary Azure AD Service Principal to represent an application or user, and provision the Azure Storage Account with the Hierarchical Namespace (HNS) enabled to function as a Data Lake Gen2. This sets the stage for applying access control.",
            "dependencies": [],
            "details": "1. Use the `azuread_service_principal` and `azuread_application` resources to create a new identity. 2. In the `azurerm_storage_account` resource, ensure the `is_hns_enabled` property is set to `true`. 3. Create an `azurerm_storage_data_lake_gen2_filesystem` resource to act as the container for the data lake paths. 4. Use `output` blocks to expose the service principal's `object_id` and the storage account `id` for use in subsequent subtasks.",
            "status": "pending",
            "testStrategy": "Run `terraform apply` and verify in the Azure Portal that the storage account is created with 'Hierarchical namespace' enabled and that the service principal exists in Azure AD."
          },
          {
            "id": 2,
            "title": "Implement Fine-Grained ACLs on Data Lake Paths",
            "description": "Demonstrate the use of Access Control Lists (ACLs) for POSIX-like permissions on specific directories and files within the data lake. This subtask will create a directory and a file, applying distinct permissions to each for the service principal.",
            "dependencies": [
              1
            ],
            "details": "1. Use the `azurerm_storage_data_lake_gen2_path` resource to create a directory (e.g., `path = \"raw\"`). Set `resource = \"directory\"`. 2. Configure the `ace` block to grant the Service Principal from subtask 1 `rwx` permissions. The `id` in the `ace` block should be the `object_id` of the service principal. 3. Add another `azurerm_storage_data_lake_gen2_path` resource to create a file inside the directory (e.g., `path = \"raw/data.csv\"`, `resource = \"file\"`). Grant this file `rw-` permissions for the same principal to show file-level control.",
            "status": "pending",
            "testStrategy": "After applying, use Azure Storage Explorer or Azure CLI (`az storage fs access show`) to inspect the ACLs on the newly created directory and file. Verify that the service principal's object ID is listed with the correct 'rwx' and 'rw-' permissions respectively."
          },
          {
            "id": 3,
            "title": "Assign Coarse-Grained RBAC Roles for Data Plane Operations",
            "description": "Complement the fine-grained ACLs by assigning a broader Azure RBAC role to the service principal. This demonstrates the two-layered security model of Azure Data Lake Storage, where RBAC provides high-level access and ACLs refine it.",
            "dependencies": [
              1
            ],
            "details": "1. Create an `azurerm_role_assignment` resource. 2. Set the `scope` to the `id` of the `azurerm_storage_account` created in subtask 1. 3. Set the `role_definition_name` to 'Storage Blob Data Contributor'. This role is commonly used for data plane operations. 4. Set the `principal_id` to the `object_id` of the service principal. 5. Add comments to the Terraform code explaining that Azure first checks RBAC for access, and if granted, then checks ACLs for the specific operation.",
            "status": "pending",
            "testStrategy": "In the Azure Portal, navigate to the Storage Account's 'Access control (IAM)' blade. Verify that the service principal has been assigned the 'Storage Blob Data Contributor' role. Test data access using a tool or script authenticated as the service principal to confirm it can write data as allowed by the combination of its RBAC role and ACLs."
          }
        ]
      },
      {
        "id": 27,
        "title": "Add Advanced Features to Data-Lake-Gen2 Example",
        "description": "Extend the Data Lake Gen2 example to showcase integration with analytics services like Databricks or Synapse and to demonstrate advanced features such as change feed.",
        "details": "1. Add commented-out or placeholder resource blocks for `azurerm_databricks_workspace` or `azurerm_synapse_workspace` with documentation explaining how to mount the Data Lake storage. 2. Enable the change feed feature on the storage account's blob service properties via the module: `change_feed_enabled = true` and `change_feed_retention_in_days = 7`. 3. Add a note in the example's README about query acceleration, explaining it's a feature enabled on-demand and not typically managed via Terraform.",
        "testStrategy": "Apply the configuration. In the Azure Portal, navigate to the storage account's 'Data protection' settings and verify that the change feed is enabled with the correct retention period. Review the generated documentation for clarity and correctness regarding analytics integration.",
        "priority": "medium",
        "dependencies": [
          23,
          26
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Enable Change Feed and Add Analytics Service Placeholders in Terraform",
            "description": "Modify the Data Lake Gen2 example's Terraform configuration to enable the change feed feature on the storage account and add commented-out resource blocks for Databricks or Synapse Analytics integration.",
            "dependencies": [],
            "details": "In the main Terraform file for the `data-lake-gen2` example, update the module call for the storage account to enable the change feed. Set `change_feed_enabled = true` and `change_feed_retention_in_days = 7`. Following this, add new, commented-out resource blocks for either `azurerm_databricks_workspace` or `azurerm_synapse_workspace`. Include detailed comments above these blocks explaining how a user would uncomment and configure them, and provide guidance or a link on how to mount the Data Lake storage to the chosen analytics service.",
            "status": "pending",
            "testStrategy": "Run `terraform validate` to check for syntax errors. Run `terraform plan` and inspect the output to confirm that the `change_feed_enabled` property on the storage account's blob service is being set to `true`. Manually review the Terraform file to ensure the commented-out analytics service resources and their accompanying documentation are clear and correct."
          },
          {
            "id": 2,
            "title": "Update README with Advanced Feature Documentation",
            "description": "Update the example's README.md to document the newly added advanced features, including the enabled change feed, the analytics service integration placeholders, and a note on query acceleration.",
            "dependencies": [
              1
            ],
            "details": "Edit the `README.md` file in the `data-lake-gen2` example directory. Create a new section, for example, 'Advanced Features'. Within this section, add subsections to: 1. Explain that the change feed feature is now enabled via the module inputs and briefly describe its use case. 2. Reference the new commented-out blocks for Databricks/Synapse in the Terraform code, explaining how to use them. 3. Add a note explaining what query acceleration is and why it's not configured via Terraform (i.e., it's an on-demand feature applied to specific queries, not the infrastructure).",
            "status": "pending",
            "testStrategy": "Review the modified `README.md` file. Check for clarity, correctness, and formatting. Ensure that all three topics (change feed, analytics integration, and query acceleration) are adequately explained for a user of the example."
          }
        ]
      },
      {
        "id": 28,
        "title": "Refactor 'Identity-Access' Example for Correctness",
        "description": "Correct the 'identity-access' example by removing direct container resources in favor of the module's parameters. Add distinct demonstrations for SystemAssigned, UserAssigned, and combined identity types, including a complete encryption flow using a managed identity with Azure Key Vault.",
        "details": "1. Remove all `azurerm_storage_container` resources from the example. 2. Refactor to use the module's `containers` input parameter. 3. Structure the example to clearly demonstrate three identity scenarios: SystemAssigned, UserAssigned, and both. 4. Implement the full customer-managed key encryption flow: create a Key Vault and key, grant the storage account's managed identity access to the vault, and configure the module's `customer_managed_key` block to use the key, e.g., `customer_managed_key = { key_vault_key_id = azurerm_key_vault_key.example.id, user_assigned_identity_id = azurerm_user_assigned_identity.example.id }`.",
        "testStrategy": "Apply each identity variation separately. For each, verify in the Azure Portal that the storage account has the correct identity type(s) enabled. Check the 'Encryption' settings to confirm it is using the specified customer-managed key from the Key Vault.",
        "priority": "high",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor Container Management to Use Module Input",
            "description": "Modify the 'identity-access' example to remove all direct `azurerm_storage_container` resource declarations. The example should instead leverage the module's `containers` input parameter to declare and manage storage containers.",
            "dependencies": [],
            "details": "In the `examples/identity-access/main.tf` file, delete all `resource \"azurerm_storage_container\" \"...\"` blocks. In the primary `module \"storage_account\"` call, add the `containers` argument to define the necessary containers. For example: `containers = { \"logs\" = {}, \"data\" = { public_access = \"None\" } }`. This ensures container configuration is handled by the module itself.",
            "status": "pending",
            "testStrategy": "Run `terraform plan`. The plan should show the module creating the containers, and there should be no direct `azurerm_storage_container` resources in the plan output."
          },
          {
            "id": 2,
            "title": "Implement Key Vault and Key for Encryption",
            "description": "Add the necessary Terraform resources to the example to provision an Azure Key Vault and a cryptographic key. This infrastructure is a prerequisite for demonstrating customer-managed key (CMK) encryption with managed identities.",
            "dependencies": [],
            "details": "In `examples/identity-access/main.tf`, add a `resource \"azurerm_key_vault\" \"example\"` and a `resource \"azurerm_key_vault_key\" \"example\"`. Configure the Key Vault with `sku_name = \"premium\"`, `soft_delete_retention_days = 7`, and `purge_protection_enabled = true`. The key should be of type 'RSA'. This creates the components needed for the encryption flow.",
            "status": "pending",
            "testStrategy": "Run `terraform apply` and verify in the Azure Portal that the Key Vault and the key within it are created successfully."
          },
          {
            "id": 3,
            "title": "Structure Identity Scenarios and Grant Key Vault Access",
            "description": "Restructure the example to clearly demonstrate three distinct identity scenarios: System-Assigned, User-Assigned, and both combined. For each scenario, create a separate module call and grant the relevant managed identity the necessary permissions ('Get', 'Wrap Key', 'Unwrap Key') on the Key Vault key.",
            "dependencies": [],
            "details": "Create three separate module calls: `module \"storage_system_assigned\"`, `module \"storage_user_assigned\"`, and `module \"storage_combined\"`. \n1. **SystemAssigned**: Set `identity_type = \"SystemAssigned\"`. Create an `azurerm_key_vault_access_policy` referencing this module's `storage_account_system_assigned_identity[0].principal_id`.\n2. **UserAssigned**: Create an `azurerm_user_assigned_identity`. Set `identity_type = \"UserAssigned\"` and pass the identity's ID to `user_assigned_identity_resource_ids`. Create an access policy for this identity's `principal_id`.\n3. **Combined**: Set `identity_type = \"SystemAssigned, UserAssigned\"`. Create an access policy for its system-assigned identity's principal ID.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` to verify that three storage accounts are planned, each with the correct identity configuration, and that three corresponding `azurerm_key_vault_access_policy` resources are created targeting the correct principal IDs."
          },
          {
            "id": 4,
            "title": "Configure CMK Encryption and Demonstrate Container RBAC",
            "description": "For each of the three identity scenarios, configure the `customer_managed_key` block to enable encryption using the Key Vault key. Also, add a demonstration of container-level RBAC by assigning a role to one of the managed identities for a specific container.",
            "dependencies": [],
            "details": "For each of the three module calls:\n1. Add the `customer_managed_key` block. For System-Assigned, it only needs the `key_vault_key_id`. For User-Assigned and Combined, it also requires the `user_assigned_identity_id`.\n   - Example for User-Assigned: `customer_managed_key = { key_vault_key_id = azurerm_key_vault_key.example.id, user_assigned_identity_id = azurerm_user_assigned_identity.example.id }`\n2. Add an `azurerm_role_assignment` resource. Assign the 'Storage Blob Data Contributor' role to a managed identity (e.g., the user-assigned identity). The scope should be a specific container, which can be retrieved from the module's output, e.g., `module.storage_user_assigned.containers[\"data\"].id`.",
            "status": "pending",
            "testStrategy": "Run `terraform apply`. In the Azure Portal, verify that all three storage accounts are created and their 'Encryption' settings are configured for a customer-managed key, pointing to the correct Key Vault key. Verify that the specified role assignment exists on the target container's 'Access control (IAM)' blade."
          }
        ]
      },
      {
        "id": 29,
        "title": "Fix and Enhance Multi-Region Example",
        "description": "Fix and enhance the 'multi-region' example by correcting the Terraform version requirement, implementing a practical replication mechanism using a Logic App, and adding monitoring and security enhancements.",
        "details": "1. Update the `required_version` in the `terraform` block to `~> 4.35.0`. 2. Add an `azurerm_logic_app_workflow` resource that triggers on a schedule to copy new blobs from the primary to the secondary storage account. 3. Add an `azurerm_monitor_metric_alert` to monitor replication status (e.g., alert if `UsedCapacity` on the secondary account does not increase over a time period). 4. Secure both storage accounts with private endpoints and restrictive Network Security Groups (NSGs). 5. Add a `README.md` file with cost estimation notes.",
        "testStrategy": "Apply the configuration. Manually trigger the Logic App and verify that a test blob is copied to the secondary storage account. In Azure Monitor, confirm the alert rule is active. Verify network isolation by checking the private endpoint connections and NSG rules in the Azure Portal.",
        "priority": "medium",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Terraform Version and Secure Storage Accounts",
            "description": "Update the Terraform provider version and implement foundational security for both storage accounts. This involves configuring private endpoints and network rules to restrict public access, ensuring a secure base for the replication logic.",
            "dependencies": [],
            "details": "1. In the main Terraform configuration file (`main.tf`), locate the `terraform` block and update the `required_version` constraint to `~> 4.35.0`.\n2. Define two `azurerm_private_endpoint` resources, one for the primary storage account and one for the secondary.\n3. Associate these private endpoints with the appropriate virtual network and subnet.\n4. Modify the `azurerm_storage_account` resources by setting `public_network_access_enabled` to `false` and configuring the `network_rules` block to default to 'Deny'.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` to verify the changes to the provider version and the creation of private endpoints. After applying, use the Azure Portal to confirm that both storage accounts have 'Public network access' disabled and that the private endpoint connections are successfully established."
          },
          {
            "id": 2,
            "title": "Implement Scheduled Blob Replication with a Logic App",
            "description": "Create an Azure Logic App workflow that periodically copies new or updated blobs from the primary storage account to the secondary one. This will serve as the practical replication mechanism for the multi-region example.",
            "dependencies": [],
            "details": "1. Add an `azurerm_logic_app_workflow` resource to your Terraform configuration.\n2. Configure the workflow with a 'Recurrence' trigger to run on a defined schedule (e.g., every 15 minutes).\n3. Define the workflow steps in the `workflow_schema` or a linked JSON file: \n   a. Use the 'List blobs' action to get files from the primary container.\n   b. Use a 'For each' loop to iterate over the listed blobs.\n   c. Inside the loop, use 'Get blob content' from the primary and 'Create blob' to write it to the secondary.\n4. Grant the Logic App's managed identity the 'Storage Blob Data Contributor' role on both storage accounts to allow it to read and write blobs.",
            "status": "pending",
            "testStrategy": "After deployment, manually upload a test file to the primary storage container. Monitor the Logic App's run history in the Azure Portal. Verify that the workflow triggers as scheduled and successfully copies the test file to the secondary storage container without errors."
          },
          {
            "id": 3,
            "title": "Configure Replication Monitoring and Add Documentation",
            "description": "Set up a monitoring alert to detect potential replication failures and create a README file to document the example's architecture, usage, and estimated costs.",
            "dependencies": [],
            "details": "1. Define an `azurerm_monitor_metric_alert` resource in Terraform.\n2. Target the secondary storage account's `UsedCapacity` metric.\n3. Configure the alert criteria to trigger if the metric's value does not increase over a specific time window (e.g., 1 hour), indicating that replication may have stalled. Set up an action group to send an email notification.\n4. Create a `README.md` file in the root of the example directory.\n5. Document the purpose of the example, the resources it creates, and provide a high-level cost estimation note covering storage, Logic App executions, and data transfer fees.",
            "status": "pending",
            "testStrategy": "To test the alert, temporarily disable the Logic App and upload a file to the primary storage. The secondary's capacity will not change, and the alert should trigger after its evaluation period. For the documentation, review the `README.md` file for clarity, completeness, and accuracy."
          }
        ]
      },
      {
        "id": 30,
        "title": "Harden Secure-Private-Endpoint Example",
        "description": "Harden the 'secure-private-endpoint' example by adding missing DNS zone links for queue and table services, explicitly disabling public network access, associating an NSG with the subnet, and ensuring all dependencies are correctly declared.",
        "details": "1. Add `azurerm_private_dns_zone_virtual_network_link` resources for `privatelink.queue.core.windows.net` and `privatelink.table.core.windows.net`. 2. In the module call, explicitly set `public_network_access_enabled = false`. 3. Create an `azurerm_network_security_group` with appropriate rules and associate it with the private endpoint's subnet using `azurerm_subnet_network_security_group_association`. 4. Update the `depends_on` block in the module call to include all four private DNS zone link resources (blob, file, queue, table) to ensure correct creation order.",
        "testStrategy": "Apply the configuration. From a virtual machine within the same VNet, use `nslookup` to resolve the FQDNs for the blob, queue, and table services, and verify they resolve to private IP addresses. In the Azure Portal, confirm that 'Public network access' is disabled on the storage account's networking blade and that the NSG is correctly associated with the subnet.",
        "priority": "high",
        "dependencies": [
          23
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Private DNS Zone VNet Links for Queue and Table Services",
            "description": "Enhance the private endpoint configuration by adding the necessary `azurerm_private_dns_zone_virtual_network_link` resources for the queue and table storage services. This ensures that DNS queries for these services from within the virtual network are resolved to their private IP addresses.",
            "dependencies": [],
            "details": "In the main Terraform configuration file for the example (`main.tf`), create two new `azurerm_private_dns_zone_virtual_network_link` resources. One will link the `privatelink.queue.core.windows.net` private DNS zone to the virtual network, and the other will link the `privatelink.table.core.windows.net` private DNS zone. Ensure you reference the existing virtual network and the respective private DNS zones correctly.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` to verify the creation of two new `azurerm_private_dns_zone_virtual_network_link` resources. After applying, verify in the Azure Portal that the virtual network is linked to the 'queue' and 'table' private DNS zones."
          },
          {
            "id": 2,
            "title": "Explicitly Disable Public Network Access on Storage Account",
            "description": "Harden the storage account by explicitly setting `public_network_access_enabled` to `false`. This enforces that all traffic must route through the private endpoint, aligning with security best practices.",
            "dependencies": [],
            "details": "Locate the module call for the storage account within the example's `main.tf`. In the `security_settings` block or as a direct argument, set `public_network_access_enabled = false`.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` to confirm the change to the `azurerm_storage_account` resource, showing `public_network_access_enabled` will be updated to `false`. After applying, attempt to access the storage account's public endpoint and verify that the connection is denied."
          },
          {
            "id": 3,
            "title": "Create and Associate an NSG with the Private Endpoint Subnet",
            "description": "Implement a Network Security Group (NSG) to control inbound and outbound traffic for the subnet hosting the private endpoints. This adds an essential layer of network-level security.",
            "dependencies": [],
            "details": "Define a new `azurerm_network_security_group` resource in `main.tf`. Add appropriate security rules as needed (e.g., a default rule to deny all inbound traffic). Then, create an `azurerm_subnet_network_security_group_association` resource to link the newly created NSG with the private endpoint's subnet.",
            "status": "pending",
            "testStrategy": "Run `terraform plan` to verify the creation of the `azurerm_network_security_group` and `azurerm_subnet_network_security_group_association` resources. After applying, check the Azure Portal to confirm the NSG is created and correctly associated with the private endpoint subnet."
          },
          {
            "id": 4,
            "title": "Update Module `depends_on` to Include All DNS Links",
            "description": "Update the `depends_on` meta-argument in the main module call to include all four private DNS zone virtual network links (blob, file, queue, and table). This prevents race conditions during deployment by ensuring the network links are fully provisioned before the private endpoints that rely on them are created.",
            "dependencies": [
              1
            ],
            "details": "In the `main.tf` file, locate the module call that creates the private endpoints. Add or update the `depends_on` block to explicitly list all four `azurerm_private_dns_zone_virtual_network_link` resources, including the two new ones for queue and table created in the first subtask. The list should reference the Terraform resource names, for example: `[azurerm_private_dns_zone_virtual_network_link.blob, azurerm_private_dns_zone_virtual_network_link.file, azurerm_private_dns_zone_virtual_network_link.queue, azurerm_private_dns_zone_virtual_network_link.table]`.",
            "status": "pending",
            "testStrategy": "Perform a full `terraform destroy` and `terraform apply` on the example to verify that the entire infrastructure provisions successfully without any dependency-related errors or race conditions."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-06-30T11:02:09.199Z",
      "updated": "2025-07-07T11:27:29.952Z",
      "description": "Tasks for master context"
    }
  }
}